{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feb 16 2024\n",
    "\n",
    "Topics\n",
    "* Volumes vs Surfaces [pial, white, inflated] (freeview)\n",
    "* fsnative vs fsaverage (T1w -> MNI)\n",
    "* surface mesh vs surface data (cells below)\n",
    "* plot sub 29 NC vals as overlay onto fsaverage inflated left hemisphere (freeview)\n",
    "* configure -> 90%, explore\n",
    "* mri_surf2surf conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import nilearn\n",
    "import nibabel as nib\n",
    "import nilearn.surface \n",
    "\n",
    "from nilearn.image import load_img, mean_img\n",
    "from nilearn import surface, plotting\n",
    "from pathlib import Path\n",
    "\n",
    "sub_29 = Path('/Users/alxmrphi/Documents/Data/BirdData/sub-29/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volumes vs Surfaces (freeview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fsnative` vs `fsaverage` \n",
    "\n",
    "In volume-based MRI, we have functional data and the anatomical data. The anatomical data is a high-resolution scan of a specific participant's brain. This is called the T1(w) image. The MNI template is an average of > 100 brains that we map to so that results from multiple subjects are alignable. \n",
    "\n",
    "In the surface world, using Freesurfer, making surfaces that are subject-specific, this is called `fsnative` space. So a specific subject's T1w VOLUME is converted into a surface that we say is in `fsnative` SPACE. \n",
    "\n",
    "Going from T1w to MNI (average template) in terms of surfaces is going from `fsnative` -> `fsaverage` (`fsaverage` brain is based on MNI template)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surfaces: mesh vs overlays\n",
    "\n",
    "A surface is defined by two arrays:\n",
    "* vertex array of coordinates\n",
    "* list of triangles (pointing to triplets of vertices in the vertex array)\n",
    "\n",
    "Can get best understanding via playing around with examples..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nilearn Surfaces\n",
    "\n",
    "* `nilearn.surface.load_surf_mesh`\n",
    "* `nilearn.surface.load_surf_data`\n",
    "\n",
    "The function `load_surf_mesh` loads the surface data that has (a) list of vertex locations and (b) the triangle (\"faces\") triplets that say which three vertices make up a specific triangle in the mesh.\n",
    "\n",
    "The function `load_surf_data` loads a value of interest to be plotted on each of the vertices. The triangles and structure are already set up to give the 'shape' of the brain, but the colours to be plotted on there are called 'overlays' and you lay the values over the mesh. \n",
    "\n",
    "The noise ceiling values are numerical values that go on top of each vertex point, so this is an 'overlay'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn\n",
    "from nilearn import datasets, surface\n",
    "fsaverage = datasets.fetch_surf_fsaverage(mesh='fsaverage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsaverage_infl_left = surface.load_surf_mesh(fsaverage.infl_left)\n",
    "print(len(fsaverage_infl_left))\n",
    "vertices, triangles = fsaverage_infl_left\n",
    "print(f\"{vertices.shape = }\")\n",
    "print(f\"{triangles.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 163,842 vertices in this surface, and 327,680 triangles.\n",
    "\n",
    "Let's look at the 7th triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangles[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This says the 7th triangle is made up of vertex 3, vertex 40975 and vertex 40977. \n",
    "\n",
    "Let's look at their coordinates and check they are all close together (coordinates are in millimetres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices[[triangles[6][0], triangles[6][1], triangles[6][2]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each has similar values, as we expect. Let's do the same for a triangle in a different place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(triangles[56564])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices[[triangles[56564][0], triangles[56564][1], triangles[56564][2]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are in a very different place (mm) from the 7th triangle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlays\n",
    "\n",
    "If (vertices, triangles) define a surface mesh, then when we plot, we want to put a single value on each vertex in the mesh. This means an overlay should have the same number of vertices as the vertex list of the mesh and a single column value to plot. That's what the noise ceiling surface values are. \n",
    "\n",
    "But first, how to go from a volume of noise ceilings to a surface?\n",
    "\n",
    "* Load the NC volumes previously calculated\n",
    "* Load a surface file that `fMRIprep` calculates and has saved (we'll use `pial_lh`)\n",
    "* Use the `surface.vol_to_surf` function to derive an overlay\n",
    "* Use `nibabel` to save it as a GIfTI image (surface-file representation)\n",
    "* Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_file = sub_29 / 'misc/sub-29_nc_volume.nii.gz'\n",
    "#pial_lh =     Path('/Users/alxmrphi/Documents/Data/BirdData/sub-29/anat/sub-29_hemi-L_pial.surf.gii')\n",
    "#inflated_lh = Path('/Users/alxmrphi/Documents/Data/BirdData/sub-29/anat/lh.inflated.gii')\n",
    "white_lh =    Path('/Users/alxmrphi/Documents/Data/BirdData/sub-29/anat/sub-29_hemi-L_white.surf.gii')\n",
    "#white_other =  Path('/Users/alxmrphi/Documents/Data/BirdData/birds_subjects/sub-29/surf/lh.white')\n",
    "\n",
    "nc_img = load_img(nc_file)\n",
    "nc_overlay = surface.vol_to_surf(nc_img, white_lh) \n",
    "\n",
    "img = nib.gifti.GiftiImage(darrays=[nib.gifti.GiftiDataArray(nc_overlay.astype(np.float32))])\n",
    "\n",
    "# CHANGE THIS TO SAVE INTO SPECIFIC SUBJECT FOLDER and call it by the correct hemisphere, fsnative, and that its derived from white matter surface reference\n",
    "nib.save(img, sub_29 / 'misc/sub29_nc_white_lh_fsnative.gii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORE\n",
    "#inflated_lh_surf = nilearn.surface.load_surf_mesh(inflated_lh)\n",
    "#pial_lh_surf = nilearn.surface.load_surf_mesh(pial_lh)\n",
    "#white_lh_surf = nilearn.surface.load_surf_mesh(white_lh)\n",
    "\n",
    "#print(inflated_lh_surf[0].shape)\n",
    "#print(pial_lh_surf[0].shape)\n",
    "#print(white_lh_surf[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice this is in `fsnative` space, which is subject-specific.\n",
    "\n",
    "Remember above we imported `fsaverage_infl_left` ? We can see how many vertices are in that mesh and compare it to subject 29 noise ceiling vertex count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsaverage_vertices, fsaverage_triangles = fsaverage_infl_left\n",
    "print(fsaverage_vertices.shape)\n",
    "print(nc_overlay.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values are different (as expected). If we want to be able to compare multiple subjects, we need to convert subject-specific overlay to one that fits on the `fsaverage` template. You do this by using a Freesurfer program called `mri_surf2surf`. This isn't available in Python and is best run from the terminal directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mri_surf2surf\n",
    "\n",
    "Need to have a folder with `fsaverage` subject and then the subject-specific Freesurfer folder for each subject (found in `/freesurfer/sourcedata/`). Then need to set environment variable $SUBJECTS_DIR to point to that location so that `mri_surf2surf` knows where to look for the data.\n",
    "\n",
    "\n",
    "It should look like\n",
    "\n",
    "    - foldername\n",
    "      - fsaverage \n",
    "      - sub-01\n",
    "      - sub-02\n",
    "      - etc ...\n",
    "\n",
    "And the `sourcedata` freesurfer data should be in each of those folders (not the fMRIprep outputs). Then in terminal set the environment variable SUBJECTS_DIR to `foldername` path by doing the following in the terminal:\n",
    "\n",
    "`SUBJECTS_DIR=/path/to/foldername`\n",
    "\n",
    "Then you're ready to run the command below (which you can do individually as not that many subjects or put it in a loop). Just be careful if doing a loop that you're not accidentally cross-loading different subjects data (by updating the source subject ID but not the sval location, for example).\n",
    "\n",
    "    mri_surf2surf --srcsubject sub-29 \\ \n",
    "                  --trgsubject fsaverage \\\n",
    "                  --hemi lh \\\n",
    "                  --sval /Users/alxmrphi/Documents/Code/src/sub29_nc_fsnative.gii \\ \n",
    "                  --tval /Users/alxmrphi/Documents/Data/BirdData/sub-29/misc/sub29_nc_fsaverage.gii\n",
    "\n",
    "\n",
    "`srcsubject` = source subject (here, subject 29)\n",
    "\n",
    "`trgsubject` = target subject (here, fsaverage because we want to convert from sub-29 -> fsaverage)\n",
    "\n",
    "`hemi` = hemisphere (everything is done per-hemisphere with surfaces because they're not modelled as being connected)\n",
    "\n",
    "`sval` = source value (what file do we want to convert?)\n",
    "\n",
    "`tval` = target value (what is the filename we want the output to be saved to?)\n",
    "\n",
    "Once this runs without issue, the new file will be saved into the location specified by `tval`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK (over next week)\n",
    "\n",
    "We want all subject data to be created on `fsnative` and `fsaverage` surfaces and saved in their data folders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can ignore everything below for now, but there if you want to play around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting with Python\n",
    "\n",
    "* Make sure `plotly` is installed for interactive plots (otherwise defaults to static `matplotlib`)\n",
    "* `!pip install plotly`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflated_lh_file = Path('/Users/alxmrphi/Documents/Data/BirdData/sub-29/surf/lh.inflated')\n",
    "pial_lh = Path('/Users/alxmrphi/Documents/Data/BirdData/sub-29/anat/sub-29_hemi-L_pial.surf.gii')\n",
    "white_lh = Path('/Users/alxmrphi/Documents/Data/BirdData/sub-29/anat/sub-29_hemi-L_white.surf.gii')\n",
    "curve_left_file = sub_29 / 'surf' / 'lh.curv'\n",
    "curv_left = surface.load_surf_data(curve_left_file)\n",
    "curv_left_sign = np.sign(curv_left)\n",
    "sub29_nc_fsaverage = nilearn.surface.load_surf_data(sub_29 / 'misc' / 'sub29_nc_fsaverage.gii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plotting.plot_surf_stat_map(\n",
    "    inflated_lh_file, nc_overlay, hemi='left',\n",
    "    bg_map=curv_left_sign,\n",
    "    threshold=5.5,\n",
    "    engine='plotly'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plotting.plot_surf_stat_map(\n",
    "    pial_lh, nc_overlay, hemi='left',\n",
    "    bg_map=curv_left_sign,\n",
    "    threshold=5.5,\n",
    "    engine='plotly'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Going to fsaverage space from fsnative\n",
    "https://neurostars.org/t/transform-from-fsaverage-to-fsnative/16568"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nib.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub29_nc_fsaverage = nilearn.surface.load_surf_data(sub_29 / 'misc' / 'sub29_nc_fsaverage.gii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curv_left = surface.load_surf_data(fsaverage.curv_left)\n",
    "curv_left_sign = np.sign(curv_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "fig = plotting.plot_surf_stat_map(\n",
    "    fsaverage.infl_right, sub29_nc_fsaverage, hemi='left',\n",
    "    title='Surface left hemisphere', colorbar=True,\n",
    "    threshold=1., bg_map=curv_left_sign,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "fig = plotting.plot_surf_stat_map(\n",
    "    fsaverage.infl_left, sub29_nc_fsaverage, hemi='left',\n",
    "    title='Surface left hemisphere', colorbar=True,\n",
    "    threshold=5.3, bg_map=curv_left_sign, bg_on_data=True,\n",
    "    engine='plotly'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glasser_lh_path = Path('/Users/alxmrphi/Downloads/lh.HCPMMP1.annot')\n",
    "glasser = nilearn.surface.load_surf_data(glasser_lh_path)\n",
    "glasser.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destrieux_atlas = datasets.fetch_atlas_surf_destrieux()\n",
    "parcellation = destrieux_atlas['map_right']\n",
    "# these are the regions we want to outline\n",
    "regions_dict = {b'G_postcentral': 'Postcentral gyrus',\n",
    "                b'G_precentral': 'Precentral gyrus'}\n",
    "\n",
    "# get indices in atlas for these labels\n",
    "regions_indices = [\n",
    "    np.where(np.array(destrieux_atlas['labels']) == region)[0][0]\n",
    "    for region in regions_dict\n",
    "]\n",
    "\n",
    "labels = list(regions_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.array(destrieux_atlas['labels']) == b'G_postcentral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1_idx = 1\n",
    "V2_idx = 4\n",
    "V3_idx = 5\n",
    "V4_idx = 6\n",
    "V8_idx = 7\n",
    "\n",
    "labels = ['V1', 'V2', 'V3', 'V4', 'V8']\n",
    "regions_indices = [1,4,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "curve_left_file = Path('/Users/alxmrphi/Documents/Data/BirdData/birds_subjects/fsaverage/surf/lh.curv')\n",
    "curv_left = surface.load_surf_data(curve_left_file)\n",
    "curv_left_sign = np.sign(curv_left)\n",
    "\n",
    "\n",
    "fig = plotting.plot_surf_stat_map(\n",
    "    fsaverage.infl_left, sub29_nc_fsaverage, hemi='left',\n",
    "    title='Surface left hemisphere', colorbar=True, view='posterior',\n",
    "    threshold=5.3, bg_map=curv_left_sign, bg_on_data=True)\n",
    "\n",
    "plotting.plot_surf_contours(fsaverage.infl_left, glasser, labels=labels,\n",
    "                            levels=regions_indices, figure=fig,\n",
    "                            legend=True, engine='plotly')\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = plotting.view_surf(fsaverage.infl_left, sub29_nc_fsaverage, threshold='98%',\n",
    "                          bg_map=fsaverage.sulc_left)\n",
    "\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = plotting.view_surf(fsaverage.infl_left, sub29_nc_fsaverage, threshold='98%',\n",
    "                          bg_map=fsaverage.sulc_left)\n",
    "\n",
    "plotting.plot_surf_contours(fsaverage.infl_left, glasser, labels=labels,\n",
    "                            levels=regions_indices, figure=view,\n",
    "                            legend=True, engine='plotly',\n",
    "                            views=['lateral'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
