{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c369dc8-82c7-468b-8f44-7a4ad8b1cb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from tqdm.notebook import tqdm\n",
    "import nibabel as nib\n",
    "import glmsingle\n",
    "from glmsingle.glmsingle import GLM_single\n",
    "import bids\n",
    "from bids import BIDSLayout\n",
    "from scipy.ndimage import zoom, binary_dilation\n",
    "import h5py\n",
    "import nibabel as nib\n",
    "from einops import rearrange\n",
    "\n",
    "dir2 = os.path.abspath('..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9948c34-52c4-45a7-9729-6ead59a5152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = Path('E:\\\\fmri_processing\\\\results')\n",
    "tc2see_version = 3 # [1, 2]\n",
    "# dataset_path = dataset_root / f\"TC2See_v{tc2see_version}\"\n",
    "dataset_path = dataset_root\n",
    "derivatives_path = dataset_path / 'derivatives_TC2See'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2e5f24-777e-458d-8519-330096d0e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create h5 file for v1 or v2 stimulus images\n",
    "from PIL import Image\n",
    "\n",
    "stimulus_images_path = Path('E:\\\\Decoding\\\\bird_data\\\\docs\\\\cropped')\n",
    "\n",
    "with h5py.File(derivatives_path / 'stimulus-images.hdf5', 'w') as f:\n",
    "    stimulus_names = []\n",
    "    for image_file_path in stimulus_images_path.iterdir():\n",
    "        stimulus_name = image_file_path.stem\n",
    "        stimulus_names.append(stimulus_name)\n",
    "        \n",
    "        class_id, image_id = stimulus_name.split('.')\n",
    "        class_id = int(class_id)\n",
    "        \n",
    "        bird_name = image_id[:-2]\n",
    "        bird_id = int(image_id[-1])\n",
    "        \n",
    "        with Image.open(image_file_path) as image:\n",
    "            data = np.array(image)\n",
    "        f[f'{stimulus_name}/data'] = data\n",
    "        f[stimulus_name].attrs['class_id'] = class_id\n",
    "        f[stimulus_name].attrs['bird_id'] = bird_id\n",
    "    f.attrs['stimulus_names'] = stimulus_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06db7713-fc94-4fe1-9dfb-b5429e3ee7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create h5 file for v3 stimulus images\n",
    "from PIL import Image\n",
    "\n",
    "dataset_layout = BIDSLayout(dataset_path / 'TC2See')\n",
    "derivatives_layout = BIDSLayout(derivatives_path / 'fmriprep')\n",
    "\n",
    "events_files = dataset_layout.get(\n",
    "    subject='03',\n",
    "    task='bird',\n",
    "    extension='tsv'\n",
    ")\n",
    "\n",
    "events_dfs = [\n",
    "    pd.read_csv(events_file.path, sep='\\t')\n",
    "    for events_file in events_files\n",
    "]\n",
    "events_dfs = [df[df['stimulus'] != '+'] for df in events_dfs]\n",
    "stimulus_paths = [np.array(df['stimulus']) for df in events_dfs]\n",
    "stimulus_paths = np.unique(np.concatenate(stimulus_paths))\n",
    "stimulus_names = [Path(p).stem for p in stimulus_paths if 'hash' not in p]\n",
    "\n",
    "stimulus_images_path = Path('X:\\\\Datasets\\\\EEG\\\\Things-concepts-and-images\\\\Main\\\\images')\n",
    "\n",
    "with h5py.File(derivatives_path / 'stimulus-images.hdf5', 'w') as f:\n",
    "    for stimulus_name in stimulus_names:\n",
    "        \n",
    "        class_name = '_'.join(stimulus_name.split('_')[:-1])\n",
    "        image_file_path = stimulus_images_path / class_name / f'{stimulus_name}.jpg'\n",
    "        \n",
    "        with Image.open(image_file_path) as image:\n",
    "            data = np.array(image)\n",
    "        \n",
    "        f[f'{stimulus_name}/data'] = data\n",
    "        f[stimulus_name].attrs['class_name'] = class_name\n",
    "    f.attrs['stimulus_names'] = stimulus_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137afb56-7c68-459f-8622-3f198ac5f960",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(events_dfs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeacdb8-dbf8-44e5-97c5-43dcc8c49092",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "stimulus_images = h5py.File(derivatives_path / 'stimulus-images.hdf5', \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0848ad-ac03-4fcd-8c1d-758400d22f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a CLIP model\n",
    "import clip\n",
    "\n",
    "print(clip.available_models())\n",
    "model_name = 'ViT-B/32'\n",
    "model, preprocess = clip.load(model_name, device=device)\n",
    "model = model.visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70b7f48-2610-4da7-8e5b-17dc90ac55c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(stimulus_id=stimulus_images.keys())\n",
    "def select_module(stimulus_id):\n",
    "    image = stimulus_images[stimulus_id]['data'][:]\n",
    "    image = Image.fromarray(image)\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    x = preprocess(image).unsqueeze(0).to(device).to(torch.float32)  # Change torch.float16 to torch.float32\n",
    "    print(x.isnan().sum(), x.isinf().sum())\n",
    "    \n",
    "    print(model.conv1)\n",
    "    x_conv1 = model.conv1(x)\n",
    "    print(model.conv1.weight.isnan().sum(), model.conv1.weight.isinf().sum())\n",
    "    print(x_conv1.isnan().sum(), x_conv1.isinf().sum())\n",
    "    \n",
    "    \n",
    "    x_conv1 = torch.nn.functional.conv2d(x, model.conv1.weight, stride=32)\n",
    "    print(x_conv1.isnan().sum(), x_conv1.isinf().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6ba556-81fd-45fd-a940-6ad0d3c6ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature visualizer\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "import math\n",
    "from einops import rearrange\n",
    "\n",
    "def vis_features(x):\n",
    "    if not isinstance(x, torch.Tensor):\n",
    "        print(type(x))\n",
    "        return\n",
    "    x = x.float().cpu()\n",
    "    print(x.shape, x.dtype)\n",
    "\n",
    "    if len(x.shape) == 3:\n",
    "        d = int(math.sqrt(x.shape[0] - 1))\n",
    "        x = rearrange(x[:-1, 0], '(h w) c -> c h w', h=d, w=d)[None]\n",
    "        \n",
    "    if len(x.shape) != 4:\n",
    "        return\n",
    "    N, C, W, H = x.shape\n",
    "    \n",
    "    print(x.mean(), x.std())\n",
    "\n",
    "    @interact(i=(0, N-1), c=(0, C-1))\n",
    "    def plot_feature_map(i, c):\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(x[i, c].cpu(), cmap=\"gray\")\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "modules = dict(model.named_modules())\n",
    "#print([(node, modules[node].__class__.__name__) for node in nodes if node in modules])\n",
    "@interact(module_name=modules.keys(), stimulus_id=stimulus_images.keys())\n",
    "def select_module(module_name, stimulus_id):\n",
    "    image = stimulus_images[stimulus_id]['data'][:]\n",
    "    print(image.min(), image.max())\n",
    "    image = Image.fromarray(image)\n",
    "    x = preprocess(image).unsqueeze(0).to(device).to(torch.float32) # Change torch.float16 to torch.float32\n",
    "    \n",
    "    #x = preprocess(image).to(device)\n",
    "    print(x.shape)\n",
    "    print(x.mean().item(), x.min().item(), x.max().item(), x.std().item())\n",
    "    \n",
    "    features = {}\n",
    "    def forward_hook(module_name, module, x_in, x_out):\n",
    "        features[module_name] = x_out.clone()\n",
    "    \n",
    "    module = modules[module_name]\n",
    "    hook_handle = module.register_forward_hook(partial(forward_hook, module_name))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model(x.float())  # Convert x to float32\n",
    "    \n",
    "    vis_features(features[module_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe30ffd-0100-4588-893c-b75aa4273e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features to save\n",
    "save_modules = {\n",
    "    '': 'embedding'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f1cc4-31ec-43da-8fb8-4a59cd1a55d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "from typing import Sequence, Dict\n",
    "\n",
    "modules = dict(model.named_modules())\n",
    "\n",
    "with h5py.File(derivatives_path / f\"{model_name.replace('/', '=')}-features.hdf5\", \"a\") as f:\n",
    "    images = list(enumerate(stimulus_images.items()))\n",
    "    N = len(images)\n",
    "    for i, (stimulus_id, stimulus_image) in tqdm(images):\n",
    "        image_data = stimulus_image['data'][:]\n",
    "        image = Image.fromarray(image_data)\n",
    "        x = preprocess(image).unsqueeze(0).to(device) #.to(torch.float16)\n",
    "\n",
    "        features = {}\n",
    "        def forward_hook(module_name, module, x_in, x_out):\n",
    "            if x_out.shape[0] == 1:\n",
    "                x_out = x_out[0]\n",
    "            features[module_name] = x_out.clone().cpu().numpy()\n",
    "        \n",
    "        hook_handles = []\n",
    "        if isinstance(save_modules, Sequence):\n",
    "            for module_name in save_modules:\n",
    "                module = modules[module_name]\n",
    "                hook_handle = module.register_forward_hook(partial(forward_hook, module_name))\n",
    "                hook_handles.append(hook_handle)\n",
    "        elif isinstance(save_modules, Dict):\n",
    "            for module_name, feature_name in save_modules.items():\n",
    "                module = modules[module_name]\n",
    "                hook_handle = module.register_forward_hook(partial(forward_hook, feature_name))\n",
    "                hook_handles.append(hook_handle)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model(x)\n",
    "            \n",
    "        for hook_handle in hook_handles:\n",
    "            hook_handle.remove()\n",
    "        \n",
    "        for feature_name, feature in features.items():\n",
    "            f.require_dataset(feature_name, (N, *feature.shape), feature.dtype)\n",
    "            f[feature_name][i] = feature\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
