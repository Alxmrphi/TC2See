{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760e725a",
   "metadata": {},
   "source": [
    "Importing Libraries:  \n",
    "Python imports and modules that are required that are imported at the start:  \n",
    "-\tos, sys, time, numpy (np alias), pandas (pd alias), matplotlib.pyplot (plt alias) ipywidgets, tqdm.notebook, nibabel, glmsingle, bids, noise_ceiling and tc2see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d455321-5f55-437b-b90d-114983b98c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from tqdm.notebook import tqdm\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "from nilearn import image\n",
    "# import glmsingle\n",
    "# from glmsingle.glmsingle import GLM_single\n",
    "import bids\n",
    "from bids import BIDSLayout\n",
    "from scipy.ndimage import zoom, binary_dilation\n",
    "import h5py\n",
    "import nibabel as nib\n",
    "from einops import rearrange\n",
    "\n",
    "dir2 = os.path.abspath('..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "    \n",
    "from noise_ceiling import (\n",
    "    compute_ncsnr,\n",
    "    compute_nc,\n",
    ")\n",
    "\n",
    "from tc2see import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bda9559",
   "metadata": {},
   "source": [
    "Defining Dataset Paths and Variables:  \n",
    "These sections focuses on establishing the paths to project directories and initializing key variables. It defines the paths to the dataset, derivatives, and preprocessed fMRI data, setting up the ways to access project data. Additionally, variables related to the dataset version, the number of runs, and the task specifications are set within this section.  \n",
    "(Adjust this path and any other path as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c854d408-ae78-4360-991f-6d0d84b0ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = Path('E:\\\\fmri_processing\\\\results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22df9105-c0b4-4a2a-8513-8596d337f383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\James\\anaconda3\\envs\\representationsLab\\Lib\\site-packages\\bids\\layout\\layout.py:516: UserWarning: Derivative indexing was requested, but no valid datasets were found in the specified locations ([WindowsPath('E:/fmri_processing/results/derivatives_TC2See/fmriprep/derivatives')]). Note that all BIDS-Derivatives datasets must meet all the requirements for BIDS-Raw datasets (a common problem is to fail to include a 'dataset_description.json' file in derivatives datasets).\n",
      "Example contents of 'dataset_description.json':\n",
      "{\"Name\": \"Example dataset\", \"BIDSVersion\": \"1.0.2\", \"GeneratedBy\": [{\"Name\": \"Example pipeline\"}]}\n",
      "  warnings.warn(\"Derivative indexing was requested, but no valid \"\n"
     ]
    }
   ],
   "source": [
    "tc2see_version = 3 # [1, 2]\n",
    "dataset_path = dataset_root\n",
    "derivatives_path = dataset_path / 'derivatives_TC2See'\n",
    "data_path = derivatives_path / 'fmriprep'\n",
    "num_runs = 6 if tc2see_version in (1, 3) else 8\n",
    "\n",
    "task = \"bird\"\n",
    "space = 'T1w' # ['T1w', 'MNI152NLin2009cAsym']\n",
    "\n",
    "subject_no = '31'\n",
    "\n",
    "# Initialize BIDSLayouts for querying files.\n",
    "dataset_layout = BIDSLayout(dataset_path / 'TC2See')\n",
    "derivatives_layout = BIDSLayout(derivatives_path / 'fmriprep', derivatives=True, validate = False)\n",
    "spm = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efe9027",
   "metadata": {},
   "source": [
    "Processing fMRI Data for Subjects:  \n",
    "This code segment focuses on configuring and preparing the environment for the analysis of the preprocessed fMRI data. First it initializes configuration variables such as subject IDs, TR duration, brain mask dilation parameters, and the number of stimuli. Then, it loads stimulus images and creates a mapping of stimulus names to unique identifiers. The code then creates an HDF5 file for storing the preprocessed fMRI data, with the filename derived from the specified version. For each subject, it initializes a group within the HDF5 file and manages the loading of the brain mask, potentially applying binary dilation if required. Various datasets within the subject's group are created to store bold data, statistics, trends, and stimulus related information. This segment ensures that the preprocessed fMRI data is well organized and structured for further analysis and interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "081c50f4-2504-4e4a-be93-bac60cb66740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fbb30470ba340bc9f5ff87b87d8ef6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject 31...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11c00cdbe394f2abd1ed2cc99dd55cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bold.shape=(236, 166634)\n",
      "bold.shape=(236, 166634)\n",
      "bold.shape=(236, 166634)\n",
      "bold.shape=(236, 166634)\n",
      "bold.shape=(236, 166634)\n",
      "bold.shape=(236, 166634)\n"
     ]
    }
   ],
   "source": [
    "#subjects = ['01', '02']\n",
    "# subjects = [str(sub) if sub >= 10 else '0'+str(sub) for sub in range(5,28)] # Subject ID to process data for\n",
    "subjects = [subject_no]\n",
    "\n",
    "num_trs = 236 #231 #229 #236 - 28,29  # Total number of TRs in the fMRI data\n",
    "\n",
    "tr = 2. # 1.97  # TR duration (in seconds)\n",
    "mask_dilations = 3  # Number of dilation iterations for the brain mask\n",
    "num_stimuli = 75 # 112  # Total number of different stimuli\n",
    "\n",
    "# Load stimulus images and create a mapping of stimulus names to unique identifiers\n",
    "stimulus_images = h5py.File(derivatives_path / 'stimulus-images.hdf5', 'r')\n",
    "stimulus_id_map = {name: i for i, name in enumerate(stimulus_images.attrs['stimulus_names'])}\n",
    "\n",
    "new_or_append = 'w' # Use 'a' for append/overwrite, 'w' for new hdf5 file\n",
    "           \n",
    "# Create or append to an HDF5 file to store preprocessed fMRI data\n",
    "with h5py.File(data_path / f'tc2see-v{tc2see_version}-bold-test-31.hdf5', new_or_append) as f:\n",
    "    for subject in tqdm(subjects):\n",
    "        if f'sub-{subject}' not in list(f.keys()):\n",
    "            try:\n",
    "                print(f\"Processing subject {subject}...\")\n",
    "\n",
    "                group = f.require_group(f'sub-{subject}')\n",
    "            \n",
    "                # Load the brain mask and perform binary dilation to include neighboring voxels\n",
    "                if spm:\n",
    "                    mask_image = nib.load(derivatives_path / f'spm/sub-{subject}/func/arsub-{subject}_task-bird_run-1_bold.nii')\n",
    "                    fmri_mask = mask_image.get_fdata()[..., 0].astype(bool)\n",
    "                    fmri_mask[:] = True\n",
    "                else:\n",
    "                    mask_image = derivatives_layout.get(\n",
    "                        subject=subject,\n",
    "                        run=1,\n",
    "                        task=task,\n",
    "                        space=space, \n",
    "                        desc='brain',\n",
    "                        extension='nii.gz',\n",
    "                    )[0].get_image()\n",
    "\n",
    "                    fmri_mask = mask_image.get_fdata().astype(bool)\n",
    "                    fmri_mask = binary_dilation(fmri_mask, iterations=mask_dilations)\n",
    "\n",
    "                num_voxels = fmri_mask.sum()\n",
    "\n",
    "                # If necessary attributes and datasets don't exist in the group, create them\n",
    "                if 'affine' not in group:\n",
    "                    group['affine'] = mask_image.affine\n",
    "                \n",
    "                #H, W, D = fmri_mask.shape\n",
    "                if 'fmri_mask' not in group:\n",
    "                    group['fmri_mask'] = fmri_mask\n",
    "                    \n",
    "                group.require_dataset('bold', shape=(num_runs, num_trs, num_voxels), dtype='f4')\n",
    "                group.require_dataset('bold_mean', shape=(num_runs, num_voxels), dtype='f4')\n",
    "                group.require_dataset('bold_std', shape=(num_runs, num_voxels), dtype='f4')\n",
    "                group.require_dataset('bold_trend', shape=(num_runs, 2, num_voxels), dtype='f4')\n",
    "                group.require_dataset('bold_trend_std', shape=(num_runs, num_voxels), dtype='f4')\n",
    "                group.require_dataset('stimulus_trs', shape=(num_runs, num_stimuli), dtype='f4')\n",
    "                group.require_dataset('stimulus_ids', shape=(num_runs, num_stimuli), dtype='i4')\n",
    "                \n",
    "                for run_id in tqdm(range(num_runs)):\n",
    "                    if spm:\n",
    "                        bold = nib.load(derivatives_path / f'spm/sub-{subject}/func/arsub-{subject}_task-bird_run-{run_id+1}_bold.nii').get_fdata()\n",
    "                    else:\n",
    "                        # Load the preprocessed fMRI data for the current subject and run\n",
    "                        bids_image = derivatives_layout.get(\n",
    "                            subject=subject,\n",
    "                            run=run_id + 1,\n",
    "                            space=space, \n",
    "                            task=task,\n",
    "                            desc='preproc', \n",
    "                            extension='nii.gz',\n",
    "                        )[0]\n",
    "                        \n",
    "                        bold = bids_image.get_image().get_fdata()\n",
    "\n",
    "                    bold = bold[fmri_mask].T  # Extract the relevant voxels\n",
    "                    print(f'{bold.shape=}')\n",
    "\n",
    "                    num_trs_run = bold.shape[0]\n",
    "                    trend_coeffs = np.stack([np.arange(num_trs_run), np.ones(shape=num_trs_run)], axis=1)\n",
    "                    \n",
    "                    # Perform linear detrending on the bold data\n",
    "                    bold_trend = np.linalg.lstsq(trend_coeffs, bold, rcond=None)[0]\n",
    "                    bold_predicted = trend_coeffs @ bold_trend\n",
    "                    bold_detrend = bold - bold_predicted\n",
    "\n",
    "                    # Load events data for the current subject and run\n",
    "                    events_file = dataset_layout.get(\n",
    "                        subject=subject,\n",
    "                        run=run_id + 1,\n",
    "                        task=task,\n",
    "                        extension='tsv'\n",
    "                    )[0]\n",
    "                    \n",
    "                    events_df = pd.read_csv(events_file.path, sep='\\t')\n",
    "                    events_df = events_df[events_df['stimulus'] != '+']\n",
    "                    stimulus_names = [Path(stimulus_path).stem for stimulus_path in events_df['stimulus']]\n",
    "                    stimulus_names = [\n",
    "                        name[:name.find('hash')-1] if \"hash\" in name else name\n",
    "                        for name in stimulus_names\n",
    "                    ]\n",
    "                    stimulus_ids = [stimulus_id_map[name] for name in stimulus_names]                    \n",
    "                    stimulus_trs = np.array(events_df['tr']).astype(np.float32)\n",
    "                    \n",
    "                    # Store various datasets in the HDF5 file\n",
    "                    group['bold'][run_id, :num_trs_run] = bold\n",
    "                    group['bold_mean'][run_id] = bold.mean(axis=0)\n",
    "                    group['bold_std'][run_id] = bold.std(axis=0)\n",
    "                    group['bold_trend'][run_id] = bold_trend\n",
    "                    group['bold_trend_std'][run_id] = bold_detrend.std(axis=0)\n",
    "                    group['stimulus_trs'][run_id] = stimulus_trs\n",
    "                    group['stimulus_ids'][run_id] = stimulus_ids\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {subject}: {e}\")\n",
    "                del f[f'sub-{subject}']\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"Subject {subject} already exists\")\n",
    "            print(f[f'sub-{subject}']['bold'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078db3c7",
   "metadata": {},
   "source": [
    "### Noise Ceiling File Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3c86be",
   "metadata": {},
   "source": [
    "Loading and Processing Events Data:  \n",
    "This part of the code focuses on loading and processing events data related to a specific subject, run, and task. It involves the extraction of information about the stimuli presented during fMRI scans and the mapping of these stimuli to unique identifiers. It prints the length of the stimulus_ids list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1cb74f5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'end' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mend\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'end' is not defined"
     ]
    }
   ],
   "source": [
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9506d02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "events_file = dataset_layout.get(\n",
    "    subject=subject_no,\n",
    "    run=1,\n",
    "    task=task,\n",
    "    extension='tsv'\n",
    ")[0]\n",
    "events_df = pd.read_csv(events_file.path, sep='\\t')\n",
    "events_df = events_df[events_df['stimulus'] != '+']\n",
    "stimulus_names = [Path(stimulus_path).stem for stimulus_path in events_df['stimulus']]\n",
    "stimulus_names = [\n",
    "    name[:name.find('hash')-1] if \"hash\" in name else name\n",
    "    for name in stimulus_names\n",
    "]\n",
    "stimulus_ids = [stimulus_id_map[name] for name in stimulus_names]\n",
    "print(len(stimulus_ids))\n",
    "\n",
    "stimulus_trs = np.array(events_df['tr']).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cf95c7",
   "metadata": {},
   "source": [
    "Loading and Processing fMRI Data:  \n",
    "In this section, the emphasis is on loading and processing fMRI data. The code sets various data processing parameters, such as TR offset and run normalization, to ensure data quality. The loaded bold data and stimulus IDs' shapes are inspected to verify their suitability for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11438a9-4914-49c3-98b0-8449a0f3ea12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Decoding\\fmri-preprocessing\\tc2see.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  run_bold = (run_bold - predicted_bold) / group['bold_trend_std'][i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 10828)\n",
      "(63, 75, 67)\n",
      "num_voxels:  10828\n",
      "(450,)\n"
     ]
    }
   ],
   "source": [
    "bold, stimulus_ids, mask, affine = load_data(\n",
    "    data_path / f'tc2see-v{tc2see_version}-bold-2.hdf5', \n",
    "    f'sub-{subject_no}', \n",
    "    tr_offset=4,\n",
    "    run_normalize='linear_trend',\n",
    "    interpolation=False,\n",
    ")\n",
    "print(bold.shape)\n",
    "print(mask.shape)\n",
    "print(\"num_voxels: \", mask.sum())\n",
    "print(stimulus_ids.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f342d1b9",
   "metadata": {},
   "source": [
    "Calculating Noise Ceiling:  \n",
    "This section focuses on computing noise ceiling metrics, including noise ceiling signal-to-noise ratio (ncsnr) and noise ceiling (nc). The generated metrics can help assess the quality and reliability of the fMRI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9b010b-4002-41fe-9082-007724f02fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncsnr = compute_ncsnr(bold, stimulus_ids) # Compute noise ceiling noise ratio\n",
    "nc = compute_nc(ncsnr, num_averages=1)\n",
    "nc_volume = np.zeros_like(mask, dtype=float)\n",
    "nc_volume[mask] = nc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95d4c42",
   "metadata": {},
   "source": [
    "Visualizing Noise Ceiling Maps:  \n",
    "In this section, the code defines a function that allows interactive visualization of noise ceiling maps. The @interact creates a graphical interface where users can adjust the value “d” to navigate through different slices along the z-axis of the noise ceiling volume. It displays the selected slice of the noise ceiling map, with a color map that highlights variations in noise ceiling values, with red indicating a high noise ceiling. This visualization aids in the examination of noise ceiling patterns within the brain's spatial dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943b8ba1-6dd6-4cdf-8da1-a1f65b30b5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9fe62e14fb54653bef18b558bc008c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=33, description='d', max=66), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "D = nc_volume.shape[2]\n",
    "@interact(d=(0, D-1), original=True)\n",
    "def show(d):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(nc_volume[:, :, d], cmap='jet', vmin=0., vmax=25,)\n",
    "\n",
    "# Visualize noise ceiling (red is high noise ceiling)\n",
    "# Left is back of the brain (visual cortex area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc54e42a",
   "metadata": {},
   "source": [
    "Generating Noise Ceiling Maps for Specific Subjects and TR Offsets:  \n",
    "This section extends the analysis to specific subjects and TR offsets. The code processes subjects individually, producing noise ceiling maps for each subject at distinct TR offsets. This approach allows for a detailed exploration of variations in noise ceilings at the subject level. These noise ceiling maps are saved as NIfTI files with names like “sub-12__noise-ceiling.nii.gz” in the directory specified by “subject_path,” which is determined by “data_path / 'noise_ceiling' / subject.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1a5c4c-42ff-414b-8b38-2f62ed344a99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 10828)\n",
      "(63, 75, 67)\n",
      "(450, 10828)\n",
      "(63, 75, 67)\n",
      "(450, 10828)\n",
      "(63, 75, 67)\n",
      "(450, 10828)\n",
      "(63, 75, 67)\n",
      "(450, 10828)\n",
      "(63, 75, 67)\n"
     ]
    }
   ],
   "source": [
    "subjects = [f'sub-{subject_no}']# 'sub-04',] # ['sub-05','sub-06', 'sub-07']\n",
    "tr_window = [0, 2, 4, 6, 8] # 4 (6 seconds) most white visible\n",
    "\n",
    "results = {}\n",
    "for subject in subjects:\n",
    "    subject_path = data_path / 'noise_ceiling' / subject\n",
    "    subject_path.mkdir(exist_ok=True, parents=True)\n",
    "    out_file_name = f'{subject}__noise-ceiling.nii.gz'\n",
    "\n",
    "    nc_series = []\n",
    "    for t_offset in tr_window:\n",
    "        bold, stimulus_ids, mask, affine = load_data(\n",
    "            derivatives_path / 'fmriprep' / f'tc2see-v{tc2see_version}-bold-2.hdf5', \n",
    "            subject, \n",
    "            tr_offset=t_offset / tr,\n",
    "            run_normalize='linear_trend',\n",
    "            interpolation=False,\n",
    "        )\n",
    "        print(bold.shape)\n",
    "        print(mask.shape)\n",
    "        ncsnr = compute_ncsnr(bold, stimulus_ids)\n",
    "        nc = compute_nc(ncsnr, num_averages=1)\n",
    "        nc_volume = np.zeros_like(mask, dtype=float)\n",
    "        nc_volume[mask] = nc\n",
    "        nc_series.append(nc_volume)\n",
    "    nc_series = np.stack(nc_series, axis=-1)\n",
    "\n",
    "    results[out_file_name] = nc_series\n",
    "    image = nib.Nifti1Image(nc_series, affine)\n",
    "    nib.save(image, subject_path / out_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c59e218",
   "metadata": {},
   "source": [
    "Generating Noise Ceiling Maps for Subject Groups and Run Combinations:  \n",
    "This part focuses on generating noise ceiling maps for subject groups, but it additionally considers specific run combinations. The code allows for examining how different combinations of runs and TR offsets impact the noise ceiling for subject groups, offering a complete assessment of data quality for these group configurations. The generated noise ceiling maps for subject groups and run combinations are saved as NIfTI files. These files are named with a format like “sub-12__run_ids_0-3__noise-ceiling.nii.gz” and are saved in the directory specified by “subject_path,” which is determined by “data_path / 'noise_ceiling' / subject.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de27f46-c31b-449a-a605-5106a0db00aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [f'sub-{subject_no}',]# 'sub-04',]\n",
    "tr_window = [0, 2, 4, 6, 8]\n",
    "run_id_groups = [[0, 3], [1, 4], [2, 5], [2], [5]] # 6 runs total\n",
    "tr = 2\n",
    "\n",
    "results = {}\n",
    "for subject in subjects:\n",
    "    subject_path = data_path / 'noise_ceiling' / subject\n",
    "    subject_path.mkdir(exist_ok=True, parents=True)\n",
    "    for run_ids in run_id_groups:\n",
    "        out_file_name = f'{subject}__run_ids_{\"-\".join([str(i) for i in run_ids])}__noise-ceiling.nii.gz'\n",
    "\n",
    "        nc_series = []\n",
    "        for t_offset in tr_window:\n",
    "            bold, stimulus_ids, mask, affine = load_data(\n",
    "                data_path / f'tc2see-v{tc2see_version}-bold-2.hdf5', \n",
    "                subject, \n",
    "                tr_offset=t_offset / tr,\n",
    "                run_normalize='linear_trend',\n",
    "                interpolation=False,\n",
    "                run_ids=run_ids,\n",
    "            )\n",
    "            ncsnr = compute_ncsnr(bold, stimulus_ids)\n",
    "            nc = compute_nc(ncsnr, num_averages=1)\n",
    "            nc_volume = np.zeros_like(mask, dtype=float)\n",
    "            nc_volume[mask] = nc\n",
    "            nc_series.append(nc_volume)\n",
    "        nc_series = np.stack(nc_series, axis=-1)\n",
    "\n",
    "        results[out_file_name] = nc_series\n",
    "        image = nib.Nifti1Image(nc_series, affine)\n",
    "        nib.save(image, subject_path / out_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4940a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
