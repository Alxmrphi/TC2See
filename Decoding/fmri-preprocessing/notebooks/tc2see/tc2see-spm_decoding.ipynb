{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from tqdm.notebook import tqdm\n",
    "import nibabel as nib\n",
    "import glmsingle\n",
    "from glmsingle.glmsingle import GLM_single\n",
    "import bids\n",
    "from bids import BIDSLayout\n",
    "from scipy.ndimage import zoom, binary_dilation\n",
    "from scipy.io import loadmat\n",
    "import h5py\n",
    "import nibabel as nib\n",
    "import re\n",
    "\n",
    "dir2 = os.path.abspath('..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "    \n",
    "from noise_ceiling import (\n",
    "    compute_ncsnr,\n",
    "    compute_nc,\n",
    "    group_repetitions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = Path('D:\\Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc2see_version = 3 # [1, 2]\n",
    "dataset_path = dataset_root / f\"TC2See_v{tc2see_version}\"\n",
    "derivatives_path = dataset_path / \"derivatives_TC2See_prdgm\"\n",
    "num_runs = 6\n",
    "\n",
    "task = \"bird\"\n",
    "subject = '03' # ['03', '04']\n",
    "glm_run = 'level1_native_singletrial'\n",
    "singletrial = True\n",
    "\n",
    "# Initialize BIDSLayouts for querying files.\n",
    "dataset_layout = BIDSLayout(dataset_path / 'TC2See_prdgm')\n",
    "#betas_path = derivatives_path / 'spm' / f\"sub-{subject}\" / glm_run\n",
    "betas_path = derivatives_path / 'spm' / glm_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 102, 64)\n",
      "(432, 125506)\n"
     ]
    }
   ],
   "source": [
    "write_file = True\n",
    "\n",
    "spm = loadmat(betas_path / 'SPM.mat')\n",
    "descrip = spm['SPM'][0][0]['Vbeta']['descrip'][0]\n",
    "stimulus_ids = []\n",
    "for i in range(len(descrip)):\n",
    "    if singletrial:\n",
    "        name = re.search ('\\d+_([a-z_]+)_\\d+', descrip[i][0])\n",
    "    else:\n",
    "        name = re.search('\\) (\\w+)\\*', descrip[i][0])\n",
    "\n",
    "    if name != None:\n",
    "        stimulus_ids.append(name.groups(1)[0])\n",
    "\n",
    "# write file\n",
    "if write_file:\n",
    "    with open(betas_path / 'image_labels.txt', 'w') as f:\n",
    "        for name in stimulus_ids:\n",
    "            f.write(name + '\\n')\n",
    "            \n",
    "# load mask\n",
    "mask = nib.load(betas_path / 'mask.nii').get_fdata().astype(bool)\n",
    "print(mask.shape)\n",
    "\n",
    "# load betas images\n",
    "betas = []\n",
    "num_betas = 432 if singletrial else 72\n",
    "\n",
    "for fnum in range(1, num_betas+1):\n",
    "    img = nib.load(betas_path / f\"beta_{fnum:04}.nii\").get_fdata()\n",
    "    img = img[mask]\n",
    "    betas.append(img)\n",
    "\n",
    "betas = np.array(betas)\n",
    "print(betas.shape)\n",
    "\n",
    "betas = (betas - betas.mean(axis=0, keepdims=True)) /  betas.std(axis=0, keepdims=True)\n",
    "stimulus_ids = np.array(stimulus_ids)\n",
    "\n",
    "model_name = 'ViT-B=32'\n",
    "embedding_name = 'embedding'\n",
    "\n",
    "with h5py.File(derivatives_path / f'{model_name}-features.hdf5', 'r') as f:\n",
    "    stimulus = f[embedding_name][:]\n",
    "    \n",
    "stimulus_images = h5py.File(derivatives_path / 'stimulus-images.hdf5', 'r')\n",
    "stimulus_keys = {k[:-4]: i for i, k in enumerate(stimulus_images.keys())}\n",
    "stimulus_ids = np.array([stimulus_keys[i] for i in stimulus_ids])\n",
    "Y = stimulus[stimulus_ids]\n",
    "\n",
    "run_mask = np.array([1,1,0,1,1,0], dtype=bool).repeat(72)\n",
    "\n",
    "X = betas[run_mask]\n",
    "Y = Y[run_mask]\n",
    "stimulus_ids = stimulus_ids[run_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 512)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=46.54\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from fracridge import FracRidgeRegressorCV\n",
    "from metrics import (\n",
    "    cosine_distance, squared_euclidean_distance, r2_score, two_versus_two,\n",
    "    two_versus_two_slow\n",
    ")\n",
    "import warnings\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.seterr(all=\"ignore\")\n",
    "\n",
    "k = 500\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "Y_pred = np.zeros_like(Y)\n",
    "for train_ids, val_ids in folds.split(X):\n",
    "    X_train, Y_train = X[train_ids], Y[train_ids]\n",
    "    X_val, Y_val = X[val_ids], Y[val_ids]\n",
    "    \n",
    "    grouped_repetitions = []\n",
    "    for i in range(2, 13):\n",
    "        x = group_repetitions(stimulus_ids[train_ids], num_repetitions=i)\n",
    "        if x is not None:\n",
    "            grouped_repetitions.append(x)\n",
    "    \n",
    "    ncsnr = compute_ncsnr(X_train, grouped_repetitions)\n",
    "    nc = compute_nc(ncsnr, num_averages=1)\n",
    "    top_ids = np.argsort(nc)[::-1][:k]\n",
    "\n",
    "    model = FracRidgeRegressorCV()\n",
    "    model.fit(X_train[:, top_ids], Y_train)\n",
    "    Y_pred[val_ids] = model.predict(X_val[:, top_ids])\n",
    "\n",
    "distances = cosine_distance(torch.from_numpy(Y[None]).float(), torch.from_numpy(Y_pred[:, None]).float())\n",
    "accuracy = round(two_versus_two(distances, stimulus_ids=stimulus_ids).item() * 100, 2) \n",
    "accuracy2 = round(two_versus_two_slow(distances, stimulus_ids=stimulus_ids) * 100, 2)\n",
    "\n",
    "print(f'{accuracy=}')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "runs=all, accuracy=64.11\n",
    "runs=[2, 5], accuracy=33.56\n",
    "runs=[0,1,3,4], accuracy=46.54"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri-preprocessing",
   "language": "python",
   "name": "fmri-preprocessing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "702e13d1f1be326fa5f114e8c6fa9d0c35861e15ba649dc66f1ad961a5f3b49e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
