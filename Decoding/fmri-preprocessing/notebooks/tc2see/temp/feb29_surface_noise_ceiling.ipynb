{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from tqdm.notebook import tqdm\n",
    "import h5py\n",
    "\n",
    "import nibabel as nib\n",
    "from nilearn import surface\n",
    "import bids\n",
    "from bids import BIDSLayout\n",
    "\n",
    "dir2 = os.path.abspath('../..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "    \n",
    "from noise_ceiling import (\n",
    "    compute_ncsnr,\n",
    "    compute_nc,\n",
    ")\n",
    "\n",
    "from tc2see import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\James\\anaconda3\\envs\\representationsLab\\Lib\\site-packages\\bids\\layout\\layout.py:516: UserWarning: Derivative indexing was requested, but no valid datasets were found in the specified locations ([WindowsPath('E:/fmri_processing/results/derivatives_TC2See/fmriprep/derivatives')]). Note that all BIDS-Derivatives datasets must meet all the requirements for BIDS-Raw datasets (a common problem is to fail to include a 'dataset_description.json' file in derivatives datasets).\n",
      "Example contents of 'dataset_description.json':\n",
      "{\"Name\": \"Example dataset\", \"BIDSVersion\": \"1.0.2\", \"GeneratedBy\": [{\"Name\": \"Example pipeline\"}]}\n",
      "  warnings.warn(\"Derivative indexing was requested, but no valid \"\n"
     ]
    }
   ],
   "source": [
    "tc2see_version = 3 # [1, 2]\n",
    "dataset_root = Path('E:\\\\fmri_processing\\\\results')\n",
    "dataset_path = dataset_root\n",
    "derivatives_path = dataset_path / 'derivatives_TC2See'\n",
    "data_path = derivatives_path / 'fmriprep'\n",
    "\n",
    "# Initialize BIDSLayouts for querying files.\n",
    "dataset_layout = BIDSLayout(dataset_path / 'TC2See')\n",
    "derivatives_layout = BIDSLayout(derivatives_path / 'fmriprep', derivatives=True, validate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c2a95617ef46b3bd2380655e4156da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject 07...\n",
      "num_voxels=163842\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877caccacc4b4ce59fe35443844173b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_trs_run=231\n",
      "num_trs_run=231\n",
      "num_trs_run=231\n",
      "num_trs_run=231\n",
      "num_trs_run=231\n",
      "num_trs_run=231\n"
     ]
    }
   ],
   "source": [
    "num_trs = 231 #231 #229 #236   # Total number of TRs in the fMRI data\n",
    "tr = 2. # 1.97  # TR duration (in seconds)\n",
    "mask_dilations = 3  # Number of dilation iterations for the brain mask\n",
    "num_stimuli = 75 # 112  # Total number of different stimuli\n",
    "\n",
    "num_runs = 6 if tc2see_version in (1, 3) else 8\n",
    "\n",
    "subject_no = '07'\n",
    "subjects = [subject_no]\n",
    "task = \"bird\"\n",
    "space = 'fsaverage' # ['T1w', 'MNI152NLin2009cAsym']\n",
    "\n",
    "# Load stimulus images and create a mapping of stimulus names to unique identifiers\n",
    "stimulus_images = h5py.File(derivatives_path / 'stimulus-images.hdf5', 'r')\n",
    "stimulus_id_map = {name: i for i, name in enumerate(stimulus_images.attrs['stimulus_names'])}\n",
    "\n",
    "new_or_append = 'w' # Use 'a' for append/overwrite, 'w' for new hdf5 file\n",
    "\n",
    "for hemi in ('L', 'R'):\n",
    "    with h5py.File(data_path / f'tc2see-v{tc2see_version}-fsaverage-surfs-{hemi}.hdf5', 'w') as f:\n",
    "        for subject in tqdm(subjects):\n",
    "            print(f\"Processing subject {subject}...\")\n",
    "            leftOrRight = 0 if hemi == 'L' else 1\n",
    "            group = f.require_group(f'sub-{subject}')\n",
    "        \n",
    "            fsaverage_surf = derivatives_layout.get(\n",
    "                    subject=subject_no,\n",
    "                    run=1,\n",
    "                    task=task,\n",
    "                    space=space, \n",
    "                    extension='func.gii',\n",
    "            )[leftOrRight]\n",
    "\n",
    "            fsaverage_surf = surface.load_surf_data(fsaverage_surf).astype(np.float64)\n",
    "\n",
    "            num_voxels = fsaverage_surf.shape[0]\n",
    "            print(f'{num_voxels=}')\n",
    "                \n",
    "            group.require_dataset('surf', shape=(num_runs, num_trs, num_voxels), dtype='f4')\n",
    "            group.require_dataset('surf_mean', shape=(num_runs, num_voxels), dtype='f4')\n",
    "            group.require_dataset('surf_std', shape=(num_runs, num_voxels), dtype='f4')\n",
    "            group.require_dataset('surf_trend', shape=(num_runs, 2, num_voxels), dtype='f4')\n",
    "            group.require_dataset('surf_trend_std', shape=(num_runs, num_voxels), dtype='f4')\n",
    "            group.require_dataset('stimulus_trs', shape=(num_runs, num_stimuli), dtype='f4')\n",
    "            group.require_dataset('stimulus_ids', shape=(num_runs, num_stimuli), dtype='i4')\n",
    "            \n",
    "            for run_id in tqdm(range(num_runs)):\n",
    "                fsaverage_surf = derivatives_layout.get(\n",
    "                    subject=subject_no,\n",
    "                    run=run_id + 1,\n",
    "                    task=task,\n",
    "                    space=space, \n",
    "                    extension='func.gii',\n",
    "                )[leftOrRight] # index 0 is left hemisphere data, 1 is right\n",
    "\n",
    "                fsaverage_surf = np.transpose(surface.load_surf_data(fsaverage_surf).astype(np.float64))\n",
    "                \n",
    "                num_trs_run = fsaverage_surf.shape[0]\n",
    "                print(f'{num_trs_run=}')\n",
    "                trend_coeffs = np.stack([np.arange(num_trs_run), np.ones(shape=num_trs_run)], axis=1)\n",
    "                \n",
    "                # Perform linear detrending on the surf data\n",
    "                surf_trend = np.linalg.lstsq(trend_coeffs, fsaverage_surf, rcond=None)[0]\n",
    "                surf_predicted = trend_coeffs @ surf_trend\n",
    "                surf_detrend = fsaverage_surf - surf_predicted\n",
    "\n",
    "                # Load events data for the current subject and run\n",
    "                events_file = dataset_layout.get(\n",
    "                    subject=subject,\n",
    "                    run=run_id + 1,\n",
    "                    task=task,\n",
    "                    extension='tsv'\n",
    "                )[0]\n",
    "                \n",
    "                events_df = pd.read_csv(events_file.path, sep='\\t')\n",
    "                events_df = events_df[events_df['stimulus'] != '+']\n",
    "                stimulus_names = [Path(stimulus_path).stem for stimulus_path in events_df['stimulus']]\n",
    "                stimulus_names = [\n",
    "                    name[:name.find('hash')-1] if \"hash\" in name else name\n",
    "                    for name in stimulus_names\n",
    "                ]\n",
    "                stimulus_ids = [stimulus_id_map[name] for name in stimulus_names]\n",
    "                \n",
    "                stimulus_trs = np.array(events_df['tr']).astype(np.float32)\n",
    "                \n",
    "                # Store various datasets in the HDF5 file\n",
    "                group['surf'][run_id, :num_trs_run] = fsaverage_surf\n",
    "                group['surf_mean'][run_id] = fsaverage_surf.mean(axis=0)\n",
    "                group['surf_std'][run_id] = fsaverage_surf.std(axis=0)\n",
    "                group['surf_trend'][run_id] = surf_trend\n",
    "                group['surf_trend_std'][run_id] = surf_detrend.std(axis=0)\n",
    "                group['stimulus_trs'][run_id] = stimulus_trs\n",
    "                group['stimulus_ids'][run_id] = stimulus_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James\\AppData\\Local\\Temp\\ipykernel_1872\\3575593899.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  run_bold = (run_bold - predicted_bold) / group['bold_trend_std'][i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 126733)\n",
      "[-1.2188748  -1.1817868   0.46749604 ...  0.848829    0.82020146\n",
      " -0.6242765 ]\n",
      "(450,)\n"
     ]
    }
   ],
   "source": [
    "for hemi in ('L', 'R'):\n",
    "    bold, stimulus_ids = load_data(\n",
    "        data_path / f'tc2see-v{tc2see_version}-fsaverage-surfs-{hemi}.hdf5', \n",
    "        f'sub-{subject_no}', \n",
    "        tr_offset=3,\n",
    "        run_normalize='linear_trend',\n",
    "        interpolation=False,\n",
    "    )\n",
    "\n",
    "    ncsnr = compute_ncsnr(bold, stimulus_ids) # Compute noise ceiling noise ratio\n",
    "    nc = compute_nc(ncsnr, num_averages=1)\n",
    "\n",
    "    img = nib.gifti.GiftiImage(darrays=[nib.gifti.GiftiDataArray(nc.astype(np.float32))])\n",
    "    nib.save(img, f'E:/fmri_processing/results/visualization/fsaverage_surface_nc/sub{subject_no}_fsaverage_surf_nc_{hemi}.gii')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "representationsLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
