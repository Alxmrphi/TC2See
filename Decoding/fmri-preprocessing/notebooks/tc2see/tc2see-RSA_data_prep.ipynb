{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import h5py\n",
    "from bids import BIDSLayout\n",
    "import nibabel as nib\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision.models import  ResNet50_Weights\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "dir2 = os.path.abspath('..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "from tc2see import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ROIs = {\n",
    "    \"FFC\": [18],\"V1\": [1],\"V2\": [4],\"V3\": [5],\"V3A\": [13],\"V3B\": [19],\"V3CD\": [158],\"V4\": [6],\"V6\": [3],\"V7\": [16],\n",
    "    \"V8\": [7], \"VMV1\": [153],\"VMV2\": [160],\"VMV3\": [154],\"LO1\": [20],\"LO2\": [21],\"PIT\": [22],\"VVC\": [163], \"140\": [140], \"11\":[11],\n",
    "    \"85\": [85], \"83\":[83], \"82\": [82], \"87\": [87], \"V1_V2_V3_V4\": [1,4,5,6], \"V1_V2\": [1,4], \"PIT_FFC_VVC\": [22, 18, 163]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [ sub for sub in range(5,40) if sub not in [13]]\n",
    "subject_strs = [ '0'+str(sub) if sub < 10 else str(sub) for sub in subjects]\n",
    "\n",
    "ROIs = {\n",
    "          \"FFC\": [18],\"V1\": [1],\"V2\": [4],\"V3\": [5],\"V3A\": [13],\"V3B\": [19],\"V3CD\": [158],\"V4\": [6],\"V6\": [3],\"V7\": [16],\n",
    "          \"V8\": [7], \"VMV1\": [153],\"VMV2\": [160],\"VMV3\": [154],\"LO1\": [20],\"LO2\": [21],\"PIT\": [22],\"VVC\": [163], \"PH\": [140], \"PEF\":[11],\n",
    "          \"IFSa\": [82], \"p9-46v\":[83], \"a9-46v\": [85], \"9a\": [87]\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = Path('E:\\\\fmri_processing\\\\results')\n",
    "dataset_path = dataset_root\n",
    "dataset_layout = BIDSLayout(dataset_path / 'TC2See')\n",
    "derivatives_path = dataset_path / 'derivatives_TC2See'\n",
    "data_path = derivatives_path / 'fmriprep'\n",
    "\n",
    "tc2see_version = 3\n",
    "tr = 2\n",
    "num_runs = 6\n",
    "\n",
    "stimulus_images = h5py.File(derivatives_path / 'stimulus-images.hdf5', 'r')\n",
    "stimulus_id_map = {i: name for i, name in enumerate(stimulus_images.attrs['stimulus_names'])}\n",
    "images_dir = Path(\"E:/Decoding/bird_data/bird_images/docs/cropped\")\n",
    "\n",
    "load_data_params = dict(\n",
    "    path = data_path / f'tc2see-v{tc2see_version}-fsaverage-surfs.hdf5', \n",
    "    tr_offset = num_runs / tr,\n",
    "    run_normalize='linear_trend',\n",
    "    interpolation=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representation Similarity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create masks for relevant ROIs or ROI combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "glasser_L = nib.freesurfer.io.read_annot(\"E:/fmri_processing/results/visualization/atlas/lh.HCPMMP1.annot\")\n",
    "glasser_R = nib.freesurfer.io.read_annot(\"E:/fmri_processing/results/visualization/atlas/rh.HCPMMP1.annot\")\n",
    "\n",
    "ROI_masks = {}\n",
    "\n",
    "for key, vals in ROIs.items():\n",
    "\n",
    "    # mask glasser atlas to mark current loop ROI as 1s\n",
    "    L_mask = np.isin(glasser_L[0], vals) # vals is a list of ROIs to set as 1\n",
    "    R_mask = np.isin(glasser_R[0], vals)\n",
    "    \n",
    "    # concatenate left and right hemispheres \n",
    "    L_R_concat_mask = np.concatenate([L_mask, R_mask], axis=0)\n",
    "    ROI_masks[key] = L_R_concat_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save ROI and layer representations to files if they haven't been saved already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[133 183 182  22 253 131 130 180 184  21 180 251  24 250 254 181 131 130\n",
      " 182 212 183 212  22 210 181 183  20 184 132 134 253 214 251  22  24 214\n",
      " 210 250  23 131 211 213  20 251 180  23  20 212 213 250  24 211 181 184\n",
      " 252  21 134 253 213 210 254 182 211 214  23  21 130 133 254 132 252 132\n",
      " 133 252 134  93 190 192  31 290  92  91 191 194  33 191 293  30 292 291\n",
      " 193  92  91 192 121 190 121  31 122 193 190  34 194  90  94 290 123 293\n",
      "  31  30 123 122 292  32  92 120 124  34 293 191  32  34 121 124 292  30\n",
      " 120 193 194 294  33  94 290 124 122 291 192 120 123  32  33  91  93 291\n",
      "  90 294  90  93 294  94 114 163 160  41 273 113 112 164 161  42 164 271\n",
      "  43 270 274 162 113 112 160 204 163 204  41 200 162 163  40 161 111 110\n",
      " 273 202 271  41  43 202 200 270  44 113 203 201  40 271 164  44  40 204\n",
      " 201 270  43 203 162 161 272  42 110 273 201 200 274 160 203 202  44  42\n",
      " 112 114 274 111 272 111 114 272 110  50 220 222 142 263  53  51 223 224\n",
      " 144 223 261 143 262 260 221  53  51 222  64 220  64 142  60 221 220 141\n",
      " 224  54  52 263  61 261 142 143  61  60 262 140  53  62  63 141 261 223\n",
      " 140 141  64  63 262 143  62 221 224 264 144  52 263  63  60 260 222  62\n",
      "  61 140 144  51  50 260  54 264  54  50 264  52  82 152 153  13 284  81\n",
      "  83 154 151  14 154 281  11 280 283 150  81  83 153 173 152 173  13 172\n",
      " 150 152  12 151  84  80 284 170 281  13  11 170 172 280  10  81 174 171\n",
      "  12 281 154  10  12 173 171 280  11 174 150 151 282  14  80 284 171 172\n",
      " 283 153 174 170  10  14  83  82 283  84 282  84  82 282  80   3 244 243\n",
      "  74 231   0   1 242 241  72 242 230  73 233 232 240   0   1 243 104 244\n",
      " 104  74 101 240 244  71 241   2   4 231 100 230  74  73 100 101 233  70\n",
      "   0 102 103  71 230 242  70  71 104 103 233  73 102 240 241 234  72   4\n",
      " 231 103 101 232 243 102 100  70  72   1   3 232   2 234   2   3 234   4]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m sparrow_file_paths \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m warbler_file_paths \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m bold_run, stimulus_ids \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mload_data_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubject\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msubject_str\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_runs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(stimulus_ids)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# bold_run = pd.DataFrame(bold_run)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# bold_run.columns = bold_run.columns.astype(str)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#         bold_run_tmp.to_parquet(bold_file_name, index=False)\u001b[39;00m\n",
      "File \u001b[1;32me:\\Decoding\\fmri-preprocessing\\tc2see.py:56\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(path, subject, tr_offset, run_normalize, interpolation, interpolation_order, run_ids)\u001b[0m\n\u001b[0;32m     53\u001b[0m run_ids \u001b[38;5;241m=\u001b[39m run_ids[in_range]\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m interpolation:\n\u001b[1;32m---> 56\u001b[0m     run_bold \u001b[38;5;241m=\u001b[39m \u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_trs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m     run_bold \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m][i]\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\James\\anaconda3\\envs\\representationsLab\\Lib\\site-packages\\h5py\\_hl\\dataset.py:758\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, args, new_dtype)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 758\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_reader\u001b[38;5;241m.\u001b[39mread(args)\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    760\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for subject_str in subject_strs:\n",
    "    sparrow_file_paths = []\n",
    "    warbler_file_paths = []\n",
    "\n",
    "    bold_run, stimulus_ids = load_data(\n",
    "        **load_data_params,\n",
    "        subject = f'sub-{subject_str}',\n",
    "        run_ids = list(range(num_runs))\n",
    "    )\n",
    "    bold_run = pd.DataFrame(bold_run)\n",
    "    bold_run.columns = bold_run.columns.astype(str)\n",
    "\n",
    "    bold_run['stimulus_ids'] = stimulus_ids\n",
    "    bold_run['stimulus_category'] = bold_run['stimulus_ids'].apply(lambda x: \"Sparrow\" if \"Sparrow\" in stimulus_id_map[x] else \"Warbler\")\n",
    "\n",
    "    numeric_bold_run = bold_run.drop(columns=['stimulus_ids', 'stimulus_category'])\n",
    "    stim_ids = bold_run['stimulus_ids'].values\n",
    "    stim_cats = bold_run['stimulus_category'].values\n",
    "            \n",
    "    # Save ROI Representations\n",
    "    for ROI, ROI_mask in ROI_masks.items():\n",
    "        roi_path = Path(\"E:/Decoding/fmri-preprocessing/img_bold_arrays\") / f\"sub_{subject_str}\" / f\"img_roi_dfs\" / \"ROIs\" / ROI\n",
    "\n",
    "        if not roi_path.exists():\n",
    "            roi_path.mkdir(parents=True, exist_ok=True)\n",
    "            bold_file_name = roi_path / \"roi_bold_for_imgs.parquet\"\n",
    "            \n",
    "            bold_run_tmp = numeric_bold_run.loc[:, ROI_mask].copy()\n",
    "            bold_run_tmp['stimulus_ids'] = stim_ids\n",
    "            bold_run_tmp['stimulus_category'] = stim_cats\n",
    "\n",
    "            bold_run_tmp.to_parquet(bold_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for subject_str in subject_strs:\n",
    "#     sparrow_file_paths = []\n",
    "#     warbler_file_paths = []\n",
    "\n",
    "#     bold_run, stimulus_ids = load_data(\n",
    "#         **load_data_params,\n",
    "#         subject = f'sub-{subject_str}',\n",
    "#         run_ids = list(range(num_runs))\n",
    "#     )\n",
    "\n",
    "#     bold_run = pd.DataFrame(bold_run)\n",
    "#     bold_run['stimulus_ids'] = stimulus_ids\n",
    "#     bold_run['stimulus_category'] = bold_run['stimulus_ids'].apply(lambda x: \"S\" if \"Sparrow\" in stimulus_id_map[x] else \"W\")\n",
    "\n",
    "#     numerical_cols = bold_run.select_dtypes(include='number').columns\n",
    "#     categorical_cols = bold_run.select_dtypes(exclude='number').columns\n",
    "\n",
    "#     # Create the aggregation dictionary\n",
    "#     agg_dict = {col: 'mean' for col in numerical_cols}\n",
    "#     agg_dict.update({col: 'first' for col in categorical_cols})\n",
    "\n",
    "\n",
    "#     # if duplicate_behaviour == 'average':\n",
    "#     #     bold_run = bold_run.groupby('stimulus_ids').agg(agg_dict)\n",
    "#     # elif duplicate_behaviour == 'average':\n",
    "#     #     bold_run = bold_run\n",
    "\n",
    "#     bold_run = bold_run.groupby('stimulus_ids').agg(agg_dict)\n",
    "#     bold_run = bold_run.sort_values(by='stimulus_category')\n",
    "    \n",
    "#     bold_run = bold_run.drop(columns=['stimulus_ids', 'stimulus_category'])\n",
    "#     bold_run = bold_run.to_numpy()\n",
    "        \n",
    "#     # Save ROI Representations\n",
    "#     for ROI, ROI_mask in ROI_masks.items():\n",
    "#         roi_path = Path(\"E:/Decoding/fmri-preprocessing/img_bold_arrays\") / f\"sub_{subject_str}\" / f\"all_runs_avg_duplicates\" / \"ROIs\" / ROI\n",
    "\n",
    "#         if not roi_path.exists():\n",
    "#             roi_path.mkdir(parents=True, exist_ok=True)\n",
    "#             bold_file_name = roi_path / \"roi_bold_for_imgs.npy\"\n",
    "#             bold_run_tmp = bold_run.copy()\n",
    "\n",
    "#             masked_bold_run = bold_run_tmp[:, ROI_mask]\n",
    "\n",
    "#             np.save(bold_file_name, masked_bold_run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "representationsLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
