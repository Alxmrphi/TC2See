{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import h5py\n",
    "from bids import BIDSLayout\n",
    "import nibabel as nib\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision.models import  ResNet50_Weights\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "dir2 = os.path.abspath('..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "from tc2see import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ROIs = {\n",
    "    \"FFC\": [18],\"V1\": [1],\"V2\": [4],\"V3\": [5],\"V3A\": [13],\"V3B\": [19],\"V3CD\": [158],\"V4\": [6],\"V6\": [3],\"V7\": [16],\n",
    "    \"V8\": [7], \"VMV1\": [153],\"VMV2\": [160],\"VMV3\": [154],\"LO1\": [20],\"LO2\": [21],\"PIT\": [22],\"VVC\": [163], \"140\": [140], \"11\":[11],\n",
    "    \"85\": [85], \"83\":[83], \"82\": [82], \"87\": [87], \"V1_V2_V3_V4\": [1,4,5,6], \"V1_V2\": [1,4], \"PIT_FFC_VVC\": [22, 18, 163]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_str = '06'\n",
    "layers = [\"layer1\", \"layer4\"]\n",
    "ROIs = {\"V1_V2\": [1,4], \"PIT_FFC_VVC\": [22, 18, 163]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = Path('E:\\\\fmri_processing\\\\results')\n",
    "dataset_path = dataset_root\n",
    "dataset_layout = BIDSLayout(dataset_path / 'TC2See')\n",
    "derivatives_path = dataset_path / 'derivatives_TC2See'\n",
    "data_path = derivatives_path / 'fmriprep'\n",
    "\n",
    "tc2see_version = 3\n",
    "tr = 2\n",
    "num_runs = 6\n",
    "\n",
    "stimulus_images = h5py.File(derivatives_path / 'stimulus-images.hdf5', 'r')\n",
    "stimulus_id_map = {i: name for i, name in enumerate(stimulus_images.attrs['stimulus_names'])}\n",
    "images_dir = Path(\"E:/Decoding/bird_data/bird_images/docs/cropped\")\n",
    "\n",
    "load_data_params = dict(\n",
    "    path = data_path / f'tc2see-v{tc2see_version}-fsaverage-surfs.hdf5', \n",
    "    tr_offset = num_runs / tr,\n",
    "    run_normalize='linear_trend',\n",
    "    interpolation=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representation Similarity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create masks for relevant ROIs or ROI combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "glasser_L = nib.freesurfer.io.read_annot(\"E:/fmri_processing/results/visualization/atlas/lh.HCPMMP1.annot\")\n",
    "glasser_R = nib.freesurfer.io.read_annot(\"E:/fmri_processing/results/visualization/atlas/rh.HCPMMP1.annot\")\n",
    "\n",
    "ROI_masks = {}\n",
    "\n",
    "for key, vals in ROIs.items():\n",
    "\n",
    "    # mask glasser atlas to mark current loop ROI as 1s\n",
    "    L_mask = np.isin(glasser_L[0], vals) # vals is a list of ROIs to set as 1\n",
    "    R_mask = np.isin(glasser_R[0], vals)\n",
    "    \n",
    "    # concatenate left and right hemispheres \n",
    "    L_R_concat_mask = np.concatenate([L_mask, R_mask], axis=0)\n",
    "    ROI_masks[key] = L_R_concat_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloader and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, file_paths, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = str(self.file_paths[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_path\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save ROI and layer representations to files if they haven't been saved already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the feature extractor\n",
    "model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "model.eval() \n",
    "\n",
    "for run_id in range(num_runs):\n",
    "\n",
    "    bold_run, stimulus_ids = load_data(\n",
    "        **load_data_params,\n",
    "        subject = f'sub-{subject_str}',\n",
    "        run_ids = [run_id]\n",
    "    )\n",
    "    \n",
    "    file_paths = [images_dir / f\"{stimulus_id_map[img_num]}.png\" for img_num in stimulus_ids]\n",
    "    dataset = CustomImageDataset(file_paths=file_paths, transform=transform)\n",
    "    data_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "    \n",
    "    #########################################################\n",
    "    ############## Save ROI Representations #################\n",
    "    #########################################################\n",
    "\n",
    "    for ROI, ROI_mask in ROI_masks.items():\n",
    "        roi_path = Path(\"E:/Decoding/fmri-preprocessing/img_bold_arrays\") / f\"sub_{subject_str}\" / f\"run_{run_id + 1}\" / \"ROIs\" / ROI\n",
    "\n",
    "        if not roi_path.exists():\n",
    "            roi_path.mkdir(parents=True, exist_ok=True)\n",
    "            bold_file_name = roi_path / \"roi_bold_for_imgs.npy\"\n",
    "            all_img_roi_data = []\n",
    "\n",
    "            for i, img in enumerate(stimulus_ids):\n",
    "                bold_copy = bold_run[i].copy()\n",
    "                bold_copy = bold_copy[ROI_mask == 1]\n",
    "                all_img_roi_data.append(bold_copy)\n",
    "\n",
    "            all_img_roi_data = np.stack(all_img_roi_data)\n",
    "            np.save(bold_file_name, all_img_roi_data)\n",
    "\n",
    "\n",
    "    #########################################################\n",
    "    ############## Save Layer Representations ###############\n",
    "    #########################################################\n",
    "    \n",
    "    # Define a hook to extract layer representations\n",
    "    def hook_fn(module, input, output):\n",
    "        global features\n",
    "        features = output\n",
    "\n",
    "    for layer_name in layers:\n",
    "        layer_path = Path(\"E:/Decoding/fmri-preprocessing/img_bold_arrays\") / f\"sub_{subject_str}\" / f\"run_{run_id + 1}\" / \"layers\" / layer_name\n",
    "        features_file_name = layer_path / \"features_for_imgs.npy\"\n",
    "        all_nn_layer_data = []\n",
    "\n",
    "        if not layer_path.exists():\n",
    "            layer_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            layer = getattr(model, layer_name)[0].relu\n",
    "            handle = layer.register_forward_hook(hook_fn)\n",
    "\n",
    "            for images, img_paths in data_loader:\n",
    "                with torch.no_grad():  \n",
    "                    _ = model(images)  # Forward pass to trigger the hook\n",
    "\n",
    "                features = features.detach().numpy().flatten()\n",
    "                all_nn_layer_data.append(features)\n",
    "\n",
    "            all_nn_layer_data = np.stack(all_nn_layer_data)\n",
    "            np.save(features_file_name, all_nn_layer_data)\n",
    "\n",
    "            # Remove the hook\n",
    "            handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train linear model using combinations of ROI representation labels and layer representation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_ROI_correlations = {}\n",
    "ROI_names = ROIs.keys()\n",
    "\n",
    "for ROI in ROI_names:\n",
    "    print(\"ROI: \", ROI)\n",
    "    layer_ROI_correlations[ROI] = {}\n",
    "    cors = {lay:[] for lay in layers}\n",
    "    for test_run_id in range(1, num_runs+1):\n",
    "        scaler = MinMaxScaler()\n",
    "        training_run_ids = list(range(1, num_runs+1))\n",
    "        training_run_ids.remove(test_run_id)\n",
    "\n",
    "        ##### Prepare testing data  #####\n",
    "        roi_testing_data = np.load(f'E:/Decoding/fmri-preprocessing/img_bold_arrays/sub_{subject_str}/run_{test_run_id}/ROIs/{ROI}/roi_bold_for_imgs.npy')\n",
    "        roi_testing_data = scaler.fit_transform(roi_testing_data) \n",
    "        layer_testing_data = [np.load(f'E:/Decoding/fmri-preprocessing/img_bold_arrays/sub_{subject_str}/run_{test_run_id}/layers/{layers[i]}/features_for_imgs.npy') for i in range(len(layers))]\n",
    "        for i, layer in enumerate(layer_testing_data.copy()):\n",
    "            layer_testing_data[i] = scaler.fit_transform(layer_testing_data[i])\n",
    "\n",
    "\n",
    "        ##### Prepare training data #####\n",
    "        roi_training_data = []\n",
    "        layer_training_data = []\n",
    "\n",
    "        for run_id in training_run_ids:\n",
    "            roi_data = np.load(f'E:/Decoding/fmri-preprocessing/img_bold_arrays/sub_{subject_str}/run_{run_id}/ROIs/{ROI}/roi_bold_for_imgs.npy')\n",
    "            layer_data = [np.load(f'E:/Decoding/fmri-preprocessing/img_bold_arrays/sub_{subject_str}/run_{run_id}/layers/{layers[i]}/features_for_imgs.npy') for i in range(len(layers))]\n",
    "\n",
    "            roi_training_data.append(roi_data)\n",
    "            layer_training_data.append(layer_data)\n",
    "        \n",
    "        # TODO: make this concatenation simpler\n",
    "        layer_training_data = [np.concatenate([layer_training_data[run_id][i] for run_id in range(len(layer_training_data))], axis=0) for i in range(len(layers))]\n",
    "\n",
    "        roi_training_data = np.concatenate(roi_training_data, axis=0)\n",
    "        roi_training_data = scaler.fit_transform(roi_training_data)\n",
    "\n",
    "        for i, layer in enumerate(layer_training_data.copy()):\n",
    "            layer_training_data[i] = scaler.fit_transform(layer_training_data[i])\n",
    "            \n",
    "\n",
    "        ##### Training Loop #####\n",
    "        for layer_idx, layer in enumerate(layers):\n",
    "            # Dimensionality reduction\n",
    "            pca_layer = PCA(n_components=.99)\n",
    "\n",
    "            print(\"Num features before PCA: \", layer_training_data[layer_idx].shape[1])\n",
    "            layer_training_data_reduced = pca_layer.fit_transform(layer_training_data[layer_idx])\n",
    "            print(\"Num features after PCA: \", layer_training_data_reduced.shape[1])\n",
    "\n",
    "            layer_testing_data_reduced = pca_layer.transform(layer_testing_data[layer_idx])\n",
    "\n",
    "            model_layer = LinearRegression()\n",
    "            model_layer.fit(layer_training_data_reduced, roi_training_data)\n",
    "\n",
    "            predictions_layer = model_layer.predict(layer_testing_data_reduced)\n",
    "\n",
    "            # Evaluate the models\n",
    "            mse_layer = float(mean_squared_error(roi_testing_data, predictions_layer))\n",
    "\n",
    "            r2_layer = r2_score(roi_testing_data, predictions_layer)\n",
    "\n",
    "            correlations = []\n",
    "\n",
    "            for i in range(predictions_layer.shape[1]):\n",
    "                corr = np.corrcoef(predictions_layer[:, i], roi_testing_data[:, i])[0, 1]\n",
    "                correlations.append(corr)\n",
    "\n",
    "            correlations = np.array(correlations)\n",
    "\n",
    "            cor_avg = correlations.mean()\n",
    "            cors[layer].append(correlations)\n",
    "\n",
    "            print(f\"\\nMean Squared Error for model using layer_training_data: {round(mse_layer, 4)}\")\n",
    "            print(f\"RÂ² Score for model using layer_training_data: {round(r2_layer, 4)}\")\n",
    "            print(f\"Avg Correlation Between {layers[layer_idx]} and ROI data: {round(cor_avg, 4)}\\n\")\n",
    "            print(\"========================================\\n\")\n",
    "\n",
    "    for layer in cors.keys():\n",
    "        cors_np = np.array(cors[layer])\n",
    "        avg_cors_for_layer = cors_np.mean()\n",
    "        layer_ROI_correlations[ROI][layer] = round(avg_cors_for_layer, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'V1_V2': {'layer1': 0.087, 'layer4': 0.08422}, 'PIT_FFC_VVC': {'layer1': -0.00207, 'layer4': 0.01682}}\n"
     ]
    }
   ],
   "source": [
    "print(layer_ROI_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('layer_ROI_correlations.json', 'w') as json_file:\n",
    "    json.dump(layer_ROI_correlations, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "representationsLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
