{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from tqdm.notebook import tqdm\n",
    "import nibabel as nib\n",
    "import glmsingle\n",
    "from glmsingle.glmsingle import GLM_single\n",
    "import bids\n",
    "from bids import BIDSLayout\n",
    "from scipy.ndimage import zoom, binary_dilation\n",
    "from scipy.io import loadmat\n",
    "import h5py\n",
    "import nibabel as nib\n",
    "import re\n",
    "\n",
    "dir2 = os.path.abspath('..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "    \n",
    "from noise_ceiling import (\n",
    "    compute_ncsnr,\n",
    "    compute_nc,\n",
    "    group_repetitions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = Path('D:\\Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc2see_version = 3 # [1, 2]\n",
    "dataset_path = dataset_root / f\"TC2See_v{tc2see_version}\"\n",
    "derivatives_path = dataset_path / \"derivatives_TC2See_prdgm\"\n",
    "num_runs = 6\n",
    "\n",
    "task = \"bird\"\n",
    "subject = '03' # ['03', '04']\n",
    "glm_run = 'level1_native_singletrial'\n",
    "singletrial = True\n",
    "\n",
    "# Initialize BIDSLayouts for querying files.\n",
    "dataset_layout = BIDSLayout(dataset_path / 'TC2See_prdgm')\n",
    "#betas_path = derivatives_path / 'spm' / f\"sub-{subject}\" / glm_run\n",
    "betas_path = derivatives_path / 'spm' / glm_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anchor', 'antelope', 'alpaca', 'aardvark', 'badger', 'beanbag', 'bag', 'basketball', 'air_pump', 'bear', 'anvil', 'biscuit', 'air_pump', 'bag', 'bear', 'beanbag', 'badger', 'anchor', 'biscuit', 'basketball', 'anvil', 'antelope', 'alpaca', 'aardvark', 'badger', 'bag', 'alpaca', 'aardvark', 'bear', 'beanbag', 'anvil', 'anchor', 'air_pump', 'basketball', 'antelope', 'biscuit', 'badger', 'alpaca', 'beanbag', 'bag', 'air_pump', 'antelope', 'aardvark', 'bear', 'anchor', 'anvil', 'basketball', 'biscuit', 'basketball', 'anvil', 'bag', 'beanbag', 'aardvark', 'air_pump', 'biscuit', 'badger', 'antelope', 'bear', 'anchor', 'alpaca', 'anvil', 'badger', 'antelope', 'basketball', 'alpaca', 'biscuit', 'air_pump', 'bag', 'beanbag', 'aardvark', 'anchor', 'bear', 'cow', 'brush', 'bison', 'dartboard', 'camel', 'dagger', 'cheesecake', 'cat', 'dalmatian', 'bull', 'box', 'chick', 'dartboard', 'box', 'bison', 'cat', 'bull', 'brush', 'dagger', 'camel', 'chick', 'dalmatian', 'cheesecake', 'cow', 'brush', 'chick', 'cow', 'bison', 'cat', 'dalmatian', 'bull', 'box', 'camel', 'dagger', 'dartboard', 'cheesecake', 'cheesecake', 'brush', 'bison', 'cat', 'chick', 'dalmatian', 'box', 'cow', 'bull', 'camel', 'dartboard', 'dagger', 'camel', 'cat', 'bull', 'cheesecake', 'box', 'dalmatian', 'chick', 'dartboard', 'cow', 'brush', 'dagger', 'bison', 'bull', 'dalmatian', 'dagger', 'camel', 'dartboard', 'brush', 'bison', 'cheesecake', 'cow', 'box', 'chick', 'cat', 'elephant', 'duck', 'drum', 'fish', 'flan', 'gorilla', 'deer', 'emerald', 'ferret', 'gavel', 'faucet', 'doorknob', 'elephant', 'flan', 'deer', 'gorilla', 'faucet', 'fish', 'gavel', 'emerald', 'drum', 'doorknob', 'ferret', 'duck', 'gavel', 'doorknob', 'faucet', 'elephant', 'gorilla', 'flan', 'drum', 'deer', 'duck', 'ferret', 'fish', 'emerald', 'ferret', 'emerald', 'faucet', 'deer', 'flan', 'gorilla', 'fish', 'drum', 'gavel', 'doorknob', 'duck', 'elephant', 'drum', 'flan', 'duck', 'faucet', 'doorknob', 'elephant', 'ferret', 'fish', 'gorilla', 'gavel', 'emerald', 'deer', 'deer', 'ferret', 'doorknob', 'drum', 'fish', 'elephant', 'faucet', 'emerald', 'flan', 'duck', 'gorilla', 'gavel', 'anvil', 'basketball', 'beanbag', 'alpaca', 'biscuit', 'antelope', 'aardvark', 'air_pump', 'bear', 'badger', 'bag', 'anchor', 'aardvark', 'badger', 'beanbag', 'anvil', 'bear', 'anchor', 'air_pump', 'alpaca', 'antelope', 'biscuit', 'basketball', 'bag', 'alpaca', 'bear', 'basketball', 'air_pump', 'antelope', 'anchor', 'anvil', 'biscuit', 'bag', 'aardvark', 'badger', 'beanbag', 'anchor', 'basketball', 'aardvark', 'bear', 'air_pump', 'badger', 'biscuit', 'anvil', 'bag', 'antelope', 'alpaca', 'beanbag', 'aardvark', 'antelope', 'anvil', 'beanbag', 'basketball', 'badger', 'air_pump', 'bag', 'biscuit', 'anchor', 'bear', 'alpaca', 'anvil', 'aardvark', 'bear', 'anchor', 'air_pump', 'badger', 'alpaca', 'antelope', 'basketball', 'beanbag', 'bag', 'biscuit', 'dagger', 'dalmatian', 'bison', 'cow', 'cheesecake', 'cat', 'camel', 'chick', 'box', 'bull', 'dartboard', 'brush', 'bull', 'box', 'camel', 'brush', 'cow', 'bison', 'dalmatian', 'dartboard', 'chick', 'cat', 'cheesecake', 'dagger', 'dagger', 'brush', 'dartboard', 'chick', 'dalmatian', 'bison', 'box', 'camel', 'cheesecake', 'cow', 'cat', 'bull', 'bison', 'bull', 'brush', 'chick', 'cheesecake', 'cow', 'dagger', 'dalmatian', 'cat', 'box', 'camel', 'dartboard', 'cat', 'dartboard', 'bison', 'cow', 'brush', 'chick', 'dagger', 'box', 'dalmatian', 'camel', 'cheesecake', 'bull', 'dagger', 'dalmatian', 'dartboard', 'cat', 'chick', 'bison', 'brush', 'cow', 'cheesecake', 'camel', 'bull', 'box', 'ferret', 'faucet', 'drum', 'deer', 'duck', 'doorknob', 'flan', 'gorilla', 'fish', 'elephant', 'emerald', 'gavel', 'emerald', 'faucet', 'drum', 'doorknob', 'deer', 'gavel', 'fish', 'ferret', 'elephant', 'flan', 'gorilla', 'duck', 'elephant', 'doorknob', 'drum', 'gorilla', 'ferret', 'duck', 'deer', 'fish', 'emerald', 'flan', 'faucet', 'gavel', 'emerald', 'faucet', 'gavel', 'doorknob', 'drum', 'flan', 'duck', 'ferret', 'fish', 'gorilla', 'elephant', 'deer', 'gorilla', 'flan', 'drum', 'fish', 'faucet', 'emerald', 'gavel', 'duck', 'doorknob', 'deer', 'elephant', 'ferret', 'flan', 'gavel', 'doorknob', 'fish', 'ferret', 'drum', 'deer', 'faucet', 'elephant', 'duck', 'gorilla', 'emerald']\n"
     ]
    }
   ],
   "source": [
    "write_file = True\n",
    "\n",
    "spm = loadmat(betas_path / 'SPM.mat')\n",
    "descrip = spm['SPM'][0][0]['Vbeta']['descrip'][0]\n",
    "stimulus_ids = []\n",
    "for i in range(len(descrip)):\n",
    "    if singletrial:\n",
    "        name = re.search ('\\d+_([a-z_]+)_\\d+', descrip[i][0])\n",
    "    else:\n",
    "        name = re.search('\\) (\\w+)\\*', descrip[i][0])\n",
    "\n",
    "    if name != None:\n",
    "        stimulus_ids.append(name.groups(1)[0])\n",
    "\n",
    "print(stimulus_ids)\n",
    "\n",
    "# write file\n",
    "if write_file:\n",
    "    with open(betas_path / 'image_labels.txt', 'w') as f:\n",
    "        for name in stimulus_ids:\n",
    "            f.write(name + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 102, 64)\n",
      "(432, 125506)\n"
     ]
    }
   ],
   "source": [
    "# load mask\n",
    "mask = nib.load(betas_path / 'mask.nii').get_fdata().astype(bool)\n",
    "print(mask.shape)\n",
    "\n",
    "# load betas images\n",
    "betas = []\n",
    "num_betas = 432 if singletrial else 72\n",
    "\n",
    "for fnum in range(1, num_betas+1):\n",
    "    img = nib.load(betas_path / f\"beta_{fnum:04}.nii\").get_fdata()\n",
    "    img = img[mask]\n",
    "    betas.append(img)\n",
    "\n",
    "betas = np.array(betas)\n",
    "print(betas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_normalized = (betas - betas.mean(axis=0, keepdims=True)) /  betas.std(axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detrending\n",
    "\n",
    "num_betas = betas.shape[0]\n",
    "trend_coeffs = np.stack([np.arange(num_betas), np.ones(shape=num_betas)], axis=1)\n",
    "betas_trend = np.linalg.lstsq(trend_coeffs, betas, rcond=None)[0]\n",
    "betas_predicted = trend_coeffs @ betas_trend\n",
    "betas_detrend = betas - betas_predicted\n",
    "betas_detrend_std = betas_detrend.std(axis=0)\n",
    "\n",
    "print(betas.mean(), betas_detrend.mean())\n",
    "print(betas.std(axis=0))\n",
    "print(betas_detrend.std(axis=0))\n",
    "\n",
    "# linear_trend normalization\n",
    "images = range(1, num_betas + 1) # treat the 72 betas as a 'run'\n",
    "trend_coeffs = np.stack([images, np.ones_like(images)], axis=1).astype(float)\n",
    "predicted_betas = trend_coeffs @ betas_trend\n",
    "betas_normalized = (betas - predicted_betas) / betas_detrend_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view mean betas\n",
    "print(betas.shape)\n",
    "print(mask.shape)\n",
    "\n",
    "betas_mean = betas_normalized.mean(axis=0)\n",
    "print(min(betas_mean), max(betas_mean))\n",
    "\n",
    "mi = min(betas_mean)\n",
    "ma = max(betas_mean)\n",
    "\n",
    "brain_volume = np.zeros_like(mask, dtype=float)\n",
    "brain_volume[mask] = betas_mean\n",
    "D = brain_volume.shape[2]\n",
    "@interact(d=(0, D-1), original=True)\n",
    "def show(d):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(brain_volume[:, :, d], cmap='bwr', vmin=mi, vmax=ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "_, stimulus_ids2 = np.unique(stimulus_ids, return_inverse=True)\n",
    "print(len(np.unique(stimulus_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_mask = np.array([1,1,1,1,1,1], dtype=bool).repeat(72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(36, 12)]\n",
      "[array([[  3,  23,  27,  42,  52,  69, 222, 228, 249, 254, 264, 277],\n",
      "       [  8,  12,  32,  40,  53,  66, 223, 234, 243, 256, 270, 280],\n",
      "       [  2,  22,  26,  37,  59,  64, 219, 235, 240, 262, 275, 282],\n",
      "       [  0,  17,  31,  44,  58,  70, 227, 233, 245, 252, 273, 279],\n",
      "       [  1,  21,  34,  41,  56,  62, 221, 236, 244, 261, 265, 283],\n",
      "       [ 10,  20,  30,  45,  49,  60, 216, 231, 246, 259, 266, 276],\n",
      "       [  4,  16,  24,  36,  55,  61, 225, 229, 250, 257, 269, 281],\n",
      "       [  6,  13,  25,  39,  50,  67, 226, 239, 248, 260, 271, 286],\n",
      "       [  7,  19,  33,  46,  48,  63, 217, 238, 242, 253, 268, 284],\n",
      "       [  5,  15,  29,  38,  51,  68, 218, 230, 251, 263, 267, 285],\n",
      "       [  9,  14,  28,  43,  57,  71, 224, 232, 241, 255, 274, 278],\n",
      "       [ 11,  18,  35,  47,  54,  65, 220, 237, 247, 258, 272, 287],\n",
      "       [ 74,  86,  99, 110, 131, 138, 290, 305, 317, 324, 338, 353],\n",
      "       [ 82,  85, 103, 114, 124, 141, 296, 301, 318, 333, 343, 359],\n",
      "       [ 73,  89,  96, 109, 129, 137, 299, 303, 313, 326, 340, 354],\n",
      "       [ 81,  88, 102, 116, 122, 132, 297, 300, 323, 325, 347, 358],\n",
      "       [ 76,  91, 104, 117, 120, 135, 294, 302, 319, 334, 345, 357],\n",
      "       [ 79,  87, 100, 111, 121, 143, 293, 309, 322, 332, 336, 351],\n",
      "       [ 78,  94, 107, 108, 123, 139, 292, 310, 320, 328, 346, 356],\n",
      "       [ 83,  92,  97, 112, 126, 142, 295, 308, 315, 327, 341, 352],\n",
      "       [ 72,  95,  98, 115, 128, 140, 291, 304, 321, 329, 339, 355],\n",
      "       [ 77,  90, 105, 119, 130, 134, 288, 311, 312, 330, 342, 348],\n",
      "       [ 80,  93, 101, 113, 125, 133, 289, 306, 316, 331, 344, 349],\n",
      "       [ 75,  84, 106, 118, 127, 136, 298, 307, 314, 335, 337, 350],\n",
      "       [150, 158, 175, 183, 203, 204, 363, 376, 390, 407, 417, 426],\n",
      "       [155, 165, 169, 189, 196, 206, 365, 375, 385, 399, 416, 422],\n",
      "       [146, 164, 174, 187, 192, 207, 362, 374, 386, 400, 410, 425],\n",
      "       [145, 167, 176, 190, 194, 213, 364, 383, 389, 402, 415, 429],\n",
      "       [144, 156, 171, 191, 197, 209, 369, 380, 384, 406, 418, 428],\n",
      "       [151, 163, 179, 181, 202, 211, 370, 372, 392, 396, 413, 431],\n",
      "       [154, 160, 170, 182, 195, 210, 361, 373, 394, 397, 412, 427],\n",
      "       [152, 166, 177, 180, 198, 205, 360, 379, 388, 403, 419, 424],\n",
      "       [147, 161, 178, 186, 199, 208, 368, 378, 391, 404, 411, 423],\n",
      "       [148, 157, 173, 184, 193, 212, 366, 381, 393, 401, 409, 420],\n",
      "       [153, 162, 168, 188, 201, 215, 371, 377, 395, 398, 414, 421],\n",
      "       [149, 159, 172, 185, 200, 214, 367, 382, 387, 405, 408, 430]],\n",
      "      dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "grouped_repetitions = []\n",
    "for i in range(2, 15):\n",
    "    x = group_repetitions(stimulus_ids2[run_mask], num_repetitions=i)\n",
    "    if x is not None:\n",
    "        grouped_repetitions.append(x)\n",
    "        \n",
    "print([x.shape for x in grouped_repetitions])\n",
    "print(grouped_repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncsnr = compute_ncsnr(betas_normalized[run_mask], grouped_repetitions)\n",
    "nc = compute_nc(ncsnr, num_averages=1)\n",
    "nc_volume = np.zeros_like(mask, dtype=float)\n",
    "nc_volume[mask] = nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mask.shape)\n",
    "print(nc_volume.shape)\n",
    "print(nc.shape)\n",
    "print(79*95*79)\n",
    "print(mask.sum())\n",
    "print(betas.shape)\n",
    "print(grouped_repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((nc_volume[:, :, 5:-5] ).max())\n",
    "print((nc_volume[:, :, 5:-5] ).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25b71be510d42f290f4e06eaef42bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=31, description='d', max=63), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot noise ceiling\n",
    "\n",
    "D = nc_volume.shape[2]\n",
    "@interact(d=(0, D-1), original=True)\n",
    "def show(d):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(nc_volume[:, :, d], cmap='jet', vmin=0, vmax=100,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save noise ceiling\n",
    "\n",
    "fname = betas_path / 'noise_ceiling__run-0-1-3-4.nii.gz'\n",
    "image = nib.Nifti1Image(nc_volume, np.eye(4))\n",
    "nib.save(image, fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri-preprocessing",
   "language": "python",
   "name": "fmri-preprocessing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "702e13d1f1be326fa5f114e8c6fa9d0c35861e15ba649dc66f1ad961a5f3b49e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
