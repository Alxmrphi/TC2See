{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760e725a",
   "metadata": {},
   "source": [
    "Importing Libraries:  \n",
    "Python imports and modules that are required that are imported at the start:  \n",
    "-\tos, sys, time, numpy (np alias), pandas (pd alias), matplotlib.pyplot (plt alias) ipywidgets, tqdm.notebook, nibabel, glmsingle, bids, noise_ceiling and tc2see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d455321-5f55-437b-b90d-114983b98c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from tqdm.notebook import tqdm\n",
    "import h5py\n",
    "\n",
    "import nibabel as nib\n",
    "from nilearn import surface\n",
    "import bids\n",
    "from bids import BIDSLayout\n",
    "\n",
    "dir2 = os.path.abspath('../')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "    \n",
    "from noise_ceiling import (\n",
    "    compute_ncsnr,\n",
    "    compute_nc,\n",
    ")\n",
    "\n",
    "from tc2see import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bda9559",
   "metadata": {},
   "source": [
    "Defining Dataset Paths and Variables:  \n",
    "These sections focuses on establishing the paths to project directories and initializing key variables. It defines the paths to the dataset, derivatives, and preprocessed fMRI data, setting up the ways to access project data. Additionally, variables related to the dataset version, the number of runs, and the task specifications are set within this section.  \n",
    "(Adjust this path and any other path as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c854d408-ae78-4360-991f-6d0d84b0ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = Path('E:\\\\fmri_processing\\\\results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22df9105-c0b4-4a2a-8513-8596d337f383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\James\\anaconda3\\envs\\representationsLab\\Lib\\site-packages\\bids\\layout\\layout.py:516: UserWarning: Derivative indexing was requested, but no valid datasets were found in the specified locations ([WindowsPath('E:/fmri_processing/results/derivatives_TC2See/fmriprep/derivatives')]). Note that all BIDS-Derivatives datasets must meet all the requirements for BIDS-Raw datasets (a common problem is to fail to include a 'dataset_description.json' file in derivatives datasets).\n",
      "Example contents of 'dataset_description.json':\n",
      "{\"Name\": \"Example dataset\", \"BIDSVersion\": \"1.0.2\", \"GeneratedBy\": [{\"Name\": \"Example pipeline\"}]}\n",
      "  warnings.warn(\"Derivative indexing was requested, but no valid \"\n"
     ]
    }
   ],
   "source": [
    "tc2see_version = 3 # [1, 2]\n",
    "dataset_path = dataset_root\n",
    "derivatives_path = dataset_path / 'derivatives_TC2See'\n",
    "data_path = derivatives_path / 'fmriprep'\n",
    "num_runs = 6 if tc2see_version in (1, 3) else 8\n",
    "\n",
    "# Initialize BIDSLayouts for querying files.\n",
    "dataset_layout = BIDSLayout(dataset_path / 'TC2See')\n",
    "derivatives_layout = BIDSLayout(derivatives_path / 'fmriprep', derivatives=True, validate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efe9027",
   "metadata": {},
   "source": [
    "Processing fMRI Data for Subjects:  \n",
    "This code segment focuses on configuring and preparing the environment for the analysis of the preprocessed fMRI data. First it initializes configuration variables such as subject IDs, TR duration, brain mask dilation parameters, and the number of stimuli. Then, it loads stimulus images and creates a mapping of stimulus names to unique identifiers. The code then creates an HDF5 file for storing the preprocessed fMRI data, with the filename derived from the specified version. For each subject, it initializes a group within the HDF5 file and manages the loading of the brain mask, potentially applying binary dilation if required. Various datasets within the subject's group are created to store bold data, statistics, trends, and stimulus related information. This segment ensures that the preprocessed fMRI data is well organized and structured for further analysis and interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "081c50f4-2504-4e4a-be93-bac60cb66740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f32aef4a040431989834945e342f8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject 18...\n",
      "(163842, 231)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 38\u001b[0m\n\u001b[0;32m     28\u001b[0m leftOrRight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hemi \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     30\u001b[0m fsaverage_surf_hemi \u001b[38;5;241m=\u001b[39m derivatives_layout\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m     31\u001b[0m         subject\u001b[38;5;241m=\u001b[39msubject,\n\u001b[0;32m     32\u001b[0m         run\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m         extension\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunc.gii\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     36\u001b[0m )[leftOrRight]\n\u001b[1;32m---> 38\u001b[0m fsaverage_surf_hemi \u001b[38;5;241m=\u001b[39m \u001b[43msurface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_surf_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfsaverage_surf_hemi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m     39\u001b[0m fsaverage_surf_list\u001b[38;5;241m.\u001b[39mappend(fsaverage_surf_hemi)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(fsaverage_surf_hemi\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\James\\anaconda3\\envs\\representationsLab\\Lib\\site-packages\\nilearn\\surface\\surface.py:783\u001b[0m, in \u001b[0;36mload_surf_data\u001b[1;34m(surf_data)\u001b[0m\n\u001b[0;32m    781\u001b[0m     data_part \u001b[38;5;241m=\u001b[39m fs\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mread_label(surf_data)\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m surf_data\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgii\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 783\u001b[0m     data_part \u001b[38;5;241m=\u001b[39m _gifti_img_to_data(\u001b[43mnibabel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msurf_data\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m surf_data\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgii.gz\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    785\u001b[0m     gii \u001b[38;5;241m=\u001b[39m _load_surf_files_gifti_gzip(surf_data)\n",
      "File \u001b[1;32mc:\\Users\\James\\anaconda3\\envs\\representationsLab\\Lib\\site-packages\\nibabel\\loadsave.py:110\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, **kwargs)\u001b[0m\n\u001b[0;32m    108\u001b[0m     is_valid, sniff \u001b[38;5;241m=\u001b[39m image_klass\u001b[38;5;241m.\u001b[39mpath_maybe_image(filename, sniff)\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid:\n\u001b[1;32m--> 110\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mimage_klass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[0;32m    113\u001b[0m matches, msg \u001b[38;5;241m=\u001b[39m _signature_matches_extension(filename)\n",
      "File \u001b[1;32mc:\\Users\\James\\anaconda3\\envs\\representationsLab\\Lib\\site-packages\\nibabel\\gifti\\gifti.py:947\u001b[0m, in \u001b[0;36mGiftiImage.from_filename\u001b[1;34m(klass, filename, buffer_size, mmap)\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_filename\u001b[39m(klass, filename, buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m35000000\u001b[39m, mmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    946\u001b[0m     file_map \u001b[38;5;241m=\u001b[39m klass\u001b[38;5;241m.\u001b[39mfilespec_to_file_map(filename)\n\u001b[1;32m--> 947\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmmap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\James\\anaconda3\\envs\\representationsLab\\Lib\\site-packages\\nibabel\\gifti\\gifti.py:940\u001b[0m, in \u001b[0;36mGiftiImage.from_file_map\u001b[1;34m(klass, file_map, buffer_size, mmap)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a Gifti image from a file_map\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \n\u001b[0;32m    915\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    937\u001b[0m \u001b[38;5;124;03mimg : GiftiImage\u001b[39;00m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    939\u001b[0m parser \u001b[38;5;241m=\u001b[39m klass\u001b[38;5;241m.\u001b[39mparser(buffer_size\u001b[38;5;241m=\u001b[39mbuffer_size, mmap\u001b[38;5;241m=\u001b[39mmmap)\n\u001b[1;32m--> 940\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfile_map\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_prepare_fileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fptr:\n\u001b[0;32m    941\u001b[0m     parser\u001b[38;5;241m.\u001b[39mparse(fptr\u001b[38;5;241m=\u001b[39mfptr)\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mimg\n",
      "File \u001b[1;32mc:\\Users\\James\\anaconda3\\envs\\representationsLab\\Lib\\site-packages\\nibabel\\fileholders.py:74\u001b[0m, in \u001b[0;36mFileHolder.get_prepare_fileobj\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m     obj\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 74\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mImageOpener\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     76\u001b[0m         obj\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos)\n",
      "File \u001b[1;32mc:\\Users\\James\\anaconda3\\envs\\representationsLab\\Lib\\site-packages\\nibabel\\openers.py:182\u001b[0m, in \u001b[0;36mOpener.__init__\u001b[1;34m(self, fileish, *args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# Clear keep_open hint if it is not relevant for the file type\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeep_open\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfobj \u001b[38;5;241m=\u001b[39m \u001b[43mopener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileish\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m fileish\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mme_opened \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "task = \"bird\"\n",
    "space = 'fsaverage' \n",
    "\n",
    "# subjects = [ '0'+str(num) if num < 10 else str(num) for num in range(5,35)]\n",
    "subjects = ['18']\n",
    "\n",
    "tr = 2. # 1.97  # TR duration (in seconds)\n",
    "mask_dilations = 3  # Number of dilation iterations for the brain mask\n",
    "num_stimuli = 75 # 112  # Total number of different stimuli\n",
    "\n",
    "# Load stimulus images and create a mapping of stimulus names to unique identifiers\n",
    "stimulus_images = h5py.File(derivatives_path / 'stimulus-images.hdf5', 'r')\n",
    "stimulus_id_map = {name: i for i, name in enumerate(stimulus_images.attrs['stimulus_names'])}\n",
    " \n",
    "new_or_append = 'w' # Use 'a' for append/overwrite, 'w' for new hdf5 file\n",
    "           \n",
    "# Create or append to an HDF5 file to store preprocessed fMRI data\n",
    "with h5py.File(data_path / f'tc2see-v{tc2see_version}-fsaverage-surf_17.hdf5', new_or_append) as f:\n",
    "    for subject in tqdm(subjects):\n",
    "        if f'sub-{subject}' not in list(f.keys()):\n",
    "            # try:\n",
    "                print(f\"Processing subject {subject}...\")\n",
    "                group = f.require_group(f'sub-{subject}')\n",
    "\n",
    "                fsaverage_surf_list = []\n",
    "                for hemi in ('L', 'R'):\n",
    "                    \n",
    "                    leftOrRight = 0 if hemi == 'L' else 1\n",
    "                \n",
    "                    fsaverage_surf_hemi = derivatives_layout.get(\n",
    "                            subject=subject,\n",
    "                            run=1,\n",
    "                            task=task,\n",
    "                            space=space, \n",
    "                            extension='func.gii',\n",
    "                    )[leftOrRight]\n",
    "\n",
    "                    fsaverage_surf_hemi = surface.load_surf_data(fsaverage_surf_hemi).astype(np.float64)\n",
    "                    fsaverage_surf_list.append(fsaverage_surf_hemi)\n",
    "                    print(fsaverage_surf_hemi.shape)\n",
    "\n",
    "                fsaverage_surf = np.concatenate(fsaverage_surf_list, axis=0)\n",
    "\n",
    "                num_voxels = fsaverage_surf.shape[0]\n",
    "                num_trs = fsaverage_surf.shape[1]\n",
    "\n",
    "                group.require_dataset('bold', shape=(num_runs, num_trs, num_voxels), dtype='f4')\n",
    "                group.require_dataset('bold_mean', shape=(num_runs, num_voxels), dtype='f4')\n",
    "                group.require_dataset('bold_std', shape=(num_runs, num_voxels), dtype='f4')\n",
    "                group.require_dataset('bold_trend', shape=(num_runs, 2, num_voxels), dtype='f4')\n",
    "                group.require_dataset('bold_trend_std', shape=(num_runs, num_voxels), dtype='f4')\n",
    "                group.require_dataset('stimulus_trs', shape=(num_runs, num_stimuli), dtype='f4')\n",
    "                group.require_dataset('stimulus_ids', shape=(num_runs, num_stimuli), dtype='i4')\n",
    "                \n",
    "                for run_id in tqdm(range(num_runs)):\n",
    "                    \n",
    "                    fsaverage_surf_list = []\n",
    "                    for hemi in ('L', 'R'):\n",
    "                        \n",
    "                        leftOrRight = 0 if hemi == 'L' else 1\n",
    "                    \n",
    "                        fsaverage_surf_hemi = derivatives_layout.get(\n",
    "                                subject=subject,\n",
    "                                run=run_id + 1,\n",
    "                                task=task,\n",
    "                                space=space, \n",
    "                                extension='func.gii',\n",
    "                        )[leftOrRight]\n",
    "\n",
    "                        fsaverage_surf_hemi = surface.load_surf_data(fsaverage_surf_hemi).astype(np.float64)\n",
    "                        print(f\"{fsaverage_surf_hemi.shape=}\") # (163842, 231)\n",
    "                        fsaverage_surf_list.append(fsaverage_surf_hemi)\n",
    "\n",
    "                    fsaverage_surf = np.concatenate(fsaverage_surf_list, axis=0) # (327684, 231)\n",
    "                    print(f\"after concat: {fsaverage_surf.shape=}\")\n",
    "                    fsaverage_surf = np.transpose(fsaverage_surf) # (231, 327684)\n",
    "                    print(f\"after transpose: {fsaverage_surf.shape=}\")\n",
    "                    print(f\"{np.mean(fsaverage_surf, axis=0)=}\")\n",
    "                    np.save(\"mean_fsaverage_surf\", np.mean(fsaverage_surf, axis=0))\n",
    "                    \n",
    "                    num_trs_run = fsaverage_surf.shape[0]\n",
    "\n",
    "                    trend_coeffs = np.stack([np.arange(num_trs_run), np.ones(shape=num_trs_run)], axis=1) # (231, 2)\n",
    "                    print(f\"{trend_coeffs.shape=}\")\n",
    "                    \n",
    "                    # Perform linear detrending on the bold data\n",
    "                    bold_trend = np.linalg.lstsq(trend_coeffs, fsaverage_surf, rcond=None)[0] # (2, 327684)\n",
    "                    print(f\"{bold_trend.shape=}\")\n",
    "                    bold_predicted = trend_coeffs @ bold_trend # (231, 327684)\n",
    "                    print(f\"{bold_predicted.shape=}\")\n",
    "                    np.save(\"bold_predicted\", bold_predicted) \n",
    "                    bold_detrend = fsaverage_surf - bold_predicted # (231, 327684)\n",
    "                    print(f\"{bold_detrend.shape=}\")\n",
    "                    np.save(\"bold_detrend\", bold_detrend)\n",
    "\n",
    "                    print(f\"{np.mean(bold_detrend, axis=0).shape=}\")\n",
    "                    np.save(\"mean_bold_detrend\", np.mean(bold_detrend, axis=0))\n",
    "\n",
    "                    # Load events data for the current subject and run\n",
    "                    events_file = dataset_layout.get(\n",
    "                        subject=subject,\n",
    "                        run=run_id + 1,\n",
    "                        task=task,\n",
    "                        extension='tsv'\n",
    "                    )[0]\n",
    "                    \n",
    "                    events_df = pd.read_csv(events_file.path, sep='\\t')\n",
    "                    events_df = events_df[events_df['stimulus'] != '+']\n",
    "                    stimulus_names = [Path(stimulus_path).stem for stimulus_path in events_df['stimulus']]\n",
    "                    stimulus_names = [\n",
    "                        name[:name.find('hash')-1] if \"hash\" in name else name\n",
    "                        for name in stimulus_names\n",
    "                    ]\n",
    "                    stimulus_ids = [stimulus_id_map[name] for name in stimulus_names]\n",
    "                    \n",
    "                    stimulus_trs = np.array(events_df['tr']).astype(np.float32)\n",
    "                    \n",
    "                    # Store various datasets in the HDF5 file\n",
    "                    group['bold'][run_id, :num_trs_run] = fsaverage_surf\n",
    "                    group['bold_mean'][run_id] = fsaverage_surf.mean(axis=0)\n",
    "                    group['bold_std'][run_id] = fsaverage_surf.std(axis=0)\n",
    "                    group['bold_trend'][run_id] = bold_trend\n",
    "                    group['bold_trend_std'][run_id] = bold_detrend.std(axis=0)\n",
    "                    group['stimulus_trs'][run_id] = stimulus_trs\n",
    "                    group['stimulus_ids'][run_id] = stimulus_ids\n",
    "                \n",
    "            # except Exception as e:\n",
    "            #     print(f\"Error processing {subject}: {e}\")\n",
    "            #     del f[f'sub-{subject}']\n",
    "            #     continue\n",
    "        else:\n",
    "            print(f\"Subject {subject} already exists\")\n",
    "            print(f[f'sub-{subject}']['bold'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ac77c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for subject in subjects:\n",
    "#     print(f\"Saving NC file for subject {subject}...\")\n",
    "#     try:\n",
    "#         bold, stimulus_ids = load_data(\n",
    "#             data_path / f'tc2see-v{tc2see_version}-fsaverage-surfs.hdf5', \n",
    "#             f'sub-{subject}', \n",
    "#             tr_offset=3,\n",
    "#             run_normalize='linear_trend',\n",
    "#             interpolation=False,\n",
    "#         )\n",
    "\n",
    "#         ncsnr = compute_ncsnr(bold, stimulus_ids) # Compute noise ceiling noise ratio\n",
    "#         nc = compute_nc(ncsnr, num_averages=1)\n",
    "\n",
    "#         img = nib.gifti.GiftiImage(darrays=[nib.gifti.GiftiDataArray(nc.astype(np.float32))])\n",
    "#         nib.save(img, f'E:/fmri_processing/results/analysis/sub-{subject}/sub{subject}_fsaverage_surf_nc.gii')\n",
    "#     except:\n",
    "#         print(f\"Error for participant {subject}, skipping...\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c802e077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
