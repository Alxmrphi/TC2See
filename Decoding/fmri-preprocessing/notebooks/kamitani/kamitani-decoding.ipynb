{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb3196a-f8e2-4b2e-a5ea-097bd05931d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from tqdm.notebook import tqdm\n",
    "import nibabel as nib\n",
    "import glmsingle\n",
    "from glmsingle.glmsingle import GLM_single\n",
    "import bids\n",
    "from bids import BIDSLayout\n",
    "from scipy.ndimage import zoom, binary_dilation\n",
    "import h5py\n",
    "import nibabel as nib\n",
    "from einops import rearrange\n",
    "\n",
    "dir2 = os.path.abspath('..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "    \n",
    "from noise_ceiling import group_repetitions, compute_nc, compute_ncsnr\n",
    "from sklearn.model_selection import KFold\n",
    "from fracridge import FracRidgeRegressorCV\n",
    "from metrics import (\n",
    "    cosine_distance, squared_euclidean_distance, r2_score, two_versus_two,\n",
    "    two_versus_two_slow\n",
    ")\n",
    "import warnings\n",
    "from kamitani import load_data, convert_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f32fa49-3d23-44cc-91d7-52559d6ce6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the path to the Kamitani dataset\n",
    "derivatives_path = Path('X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\')\n",
    "derivatives_path_ssd = Path('D:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\')\n",
    "dataset_path = derivatives_path / 'fmriprep-20.2.4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dc309b-6769-421b-873f-583120ec9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "bold, stimulus_ids, mask, affine = load_data(\n",
    "    derivatives_path_ssd / 'kamitani-bold.hdf5', \n",
    "    'sub-02', \n",
    "    tr_offset=4,\n",
    "    run_normalize='linear_trend',\n",
    "    session_normalize=False\n",
    ")\n",
    "stimulus_images = h5py.File(derivatives_path / 'stimulus_images.hdf5', \"r\")\n",
    "stimulus_ids = np.array(convert_ids(stimulus_ids, list(stimulus_images.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b832e3d-d00e-4100-b71b-55151333266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_repetitions(stimulus_ids, 5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be6f888-0375-40f5-ac40-a6f78a0575ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bold.copy()\n",
    "X_nan = np.isnan(X)\n",
    "X[X_nan] = 0.\n",
    "X_nan.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c0f177-ff5b-4bbe-bbf4-80e62582b229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834a7277-f667-4f94-b0ad-d685c372dc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_group_ids[train_image_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17d1fea-381f-41c6-aba7-256b95bf03cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.seterr(all=\"ignore\")\n",
    "\n",
    "search_space = [(3, 50), (6, 25), (10, 15), (15, 10)]\n",
    "\n",
    "num_images = 50\n",
    "num_repetitions = 24\n",
    "group_ids = group_repetitions(stimulus_ids, num_repetitions)\n",
    "\n",
    "def shuffle_along_axis(a, axis):\n",
    "    idx = np.random.rand(*a.shape).argsort(axis=axis)\n",
    "    return np.take_along_axis(a,idx,axis=axis)\n",
    "\n",
    "for select_num_repetitions, select_num_images in search_space:\n",
    "    \n",
    "    select_image_ids = np.arange(num_images)\n",
    "    np.random.shuffle(select_image_ids)\n",
    "    select_image_ids = select_image_ids[:select_num_images]\n",
    "    \n",
    "    select_group_ids = shuffle_along_axis(group_ids, 1)\n",
    "    select_group_ids = select_group_ids[select_image_ids, :select_num_repetitions]\n",
    "    \n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    \n",
    "    Y_true = []\n",
    "    Y_pred = []\n",
    "    Y_stimulus_ids = []\n",
    "    for train_image_ids, val_image_ids in folds.split(np.arange(select_num_images)):\n",
    "        train_ids = select_group_ids[train_image_ids].flatten()\n",
    "        val_ids = select_group_ids[val_image_ids].flatten()\n",
    "        \n",
    "        X_train, Y_train = X[train_ids], Y[train_ids]\n",
    "        X_val, Y_val = X[val_ids], Y[val_ids]\n",
    "        \n",
    "        ncsnr = compute_ncsnr(X_train, np.arange(train_ids.shape[0]).reshape(train_image_ids.shape[0], -1))\n",
    "        nc = compute_nc(ncsnr, num_averages=1)\n",
    "        \n",
    "        threshold = 30\n",
    "        X_train = X_train[:, nc > threshold]\n",
    "        X_val = X_val[:, nc > threshold]\n",
    "        \n",
    "        model = FracRidgeRegressorCV()\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred.append(model.predict(X_val))\n",
    "        Y_true.append(Y_val)\n",
    "        Y_stimulus_ids.append(stimulus_ids[val_ids])\n",
    "    Y_pred = np.concatenate(Y_pred)\n",
    "    Y_true = np.concatenate(Y_true)\n",
    "    Y_stimulus_ids = np.concatenate(Y_stimulus_ids)\n",
    "    \n",
    "    distances = cosine_distance(torch.from_numpy(Y_true[None]).float(), torch.from_numpy(Y_pred[:, None]).float())\n",
    "    accuracy = round(two_versus_two(distances, stimulus_ids=Y_stimulus_ids).item() * 100, 2) \n",
    "\n",
    "    print(f'{select_num_repetitions=}, {select_num_images=}, {accuracy=}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1b4b7bb-fe16-432c-98ad-0ca4dab2c071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-02\n",
      "num_voxels=2500, num_repetitions=2, num_images=75, accuracy=71.66\n",
      "num_voxels=2500, num_repetitions=3, num_images=50, accuracy=84.12\n",
      "num_voxels=2500, num_repetitions=4, num_images=38, accuracy=78.81\n",
      "num_voxels=2500, num_repetitions=5, num_images=30, accuracy=82.02\n",
      "num_voxels=2500, num_repetitions=2, num_images=30, accuracy=71.84\n",
      "num_voxels=2500, num_repetitions=3, num_images=10, accuracy=70.96\n",
      "num_voxels=2500, num_repetitions=4, num_images=15, accuracy=64.82\n",
      "num_voxels=2500, num_repetitions=5, num_images=12, accuracy=72.76\n",
      "sub-03\n",
      "num_voxels=2500, num_repetitions=2, num_images=75, accuracy=82.02\n",
      "num_voxels=2500, num_repetitions=3, num_images=50, accuracy=85.5\n",
      "num_voxels=2500, num_repetitions=4, num_images=38, accuracy=87.87\n",
      "num_voxels=2500, num_repetitions=5, num_images=30, accuracy=82.52\n",
      "num_voxels=2500, num_repetitions=2, num_images=30, accuracy=79.46\n",
      "num_voxels=2500, num_repetitions=3, num_images=10, accuracy=77.54\n",
      "num_voxels=2500, num_repetitions=4, num_images=15, accuracy=75.97\n",
      "num_voxels=2500, num_repetitions=5, num_images=12, accuracy=73.1\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "np.seterr(all=\"ignore\")\n",
    "\n",
    "search_space = [\n",
    "    #(2, 1200), (3, 800), (4, 600), (5, 480),\n",
    "    #(2, 600), (3, 400), (4, 300), (5, 240),\n",
    "    #(2, 300), (3, 200), (4, 150), (5, 120),\n",
    "    #(2, 150), (3, 100), (4, 75), (5, 60),\n",
    "    (2, 75), (3, 50), (4, 38), (5, 30),\n",
    "    (2, 30), (3, 10), (4, 15), (5, 12),\n",
    "]\n",
    "\n",
    "num_train_images = 1200\n",
    "num_train_repetitions = 5\n",
    "\n",
    "tr_offset = 4\n",
    "subjects = ['sub-02', 'sub-03']\n",
    "\n",
    "top_k_voxels_space = [2500]\n",
    "\n",
    "model_name = 'ViT-B=32'\n",
    "embedding_name = 'embedding'\n",
    "with h5py.File(derivatives_path / f'{model_name}-features.hdf5', 'r') as f:\n",
    "    stimulus = f[embedding_name][:]\n",
    "stimulus_images = h5py.File(derivatives_path / 'stimulus_images.hdf5', \"r\")\n",
    "\n",
    "\n",
    "def shuffle_along_axis(a, axis):\n",
    "    idx = np.random.rand(*a.shape).argsort(axis=axis)\n",
    "    return np.take_along_axis(a,idx,axis=axis)\n",
    "\n",
    "for subject in subjects:\n",
    "    print(subject)\n",
    "    train_bold, train_stimulus_ids, _, _ = load_data(\n",
    "        derivatives_path_ssd / 'kamitani-bold.hdf5', \n",
    "        subject, \n",
    "        tr_offset=tr_offset,\n",
    "        run_normalize='linear_trend',\n",
    "        session_normalize=False\n",
    "    )\n",
    "    train_stimulus_ids = np.array(convert_ids(train_stimulus_ids, list(stimulus_images.keys())))\n",
    "    train_bold_nan = np.isnan(train_bold)\n",
    "    train_bold[train_bold_nan] = 0.\n",
    "    train_group_ids = group_repetitions(train_stimulus_ids, num_train_repetitions)\n",
    "    \n",
    "    bold, stimulus_ids, mask, affine = load_data(\n",
    "        derivatives_path_ssd / 'kamitani-test-bold.hdf5', \n",
    "        subject, \n",
    "        tr_offset=tr_offset,\n",
    "        run_normalize='linear_trend',\n",
    "        session_normalize=False\n",
    "    )\n",
    "    stimulus_ids = np.array(convert_ids(stimulus_ids, list(stimulus_images.keys())))\n",
    "    bold_nan = np.isnan(bold)\n",
    "    bold[bold_nan] = 0.\n",
    "    \n",
    "    stimulus_images = h5py.File(derivatives_path / 'stimulus_images.hdf5', \"r\")\n",
    "    \n",
    "    Y_train = stimulus[train_stimulus_ids]\n",
    "    Y = stimulus[stimulus_ids]\n",
    "    \n",
    "    for select_num_repetitions, select_num_images in search_space:\n",
    "        select_image_ids = np.arange(num_train_images)\n",
    "        np.random.shuffle(select_image_ids)\n",
    "        select_image_ids = select_image_ids[:select_num_images]\n",
    "\n",
    "        select_group_ids = shuffle_along_axis(train_group_ids, 1)\n",
    "        select_group_ids = select_group_ids[select_image_ids, :select_num_repetitions]\n",
    "        select_group_ids = select_group_ids.flatten()\n",
    "        \n",
    "        X_nc = train_bold[select_group_ids]\n",
    "        \n",
    "        ncsnr = compute_ncsnr(X_nc, group_repetitions(train_stimulus_ids[select_group_ids], select_num_repetitions))\n",
    "        nc = compute_nc(ncsnr, num_averages=1)\n",
    "        nc[np.isnan(nc)] = 0.\n",
    "        nc_volume = np.zeros_like(mask, dtype=float)\n",
    "        nc_volume[mask] = nc\n",
    "\n",
    "        subject_path = derivatives_path_ssd / 'noise_ceiling' / subject\n",
    "        subject_path.mkdir(exist_ok=True, parents=True)\n",
    "        out_file_name = f'{subject}__repetitions-{select_num_repetitions}__images-{select_num_images}__noise-ceiling.nii.gz'\n",
    "        \n",
    "        image = nib.Nifti1Image(nc_volume, affine)\n",
    "        nib.save(image, subject_path / out_file_name)\n",
    "        \n",
    "        for top_k_voxels in top_k_voxels_space:\n",
    "            selected_voxels = np.argsort(nc)[::-1][:top_k_voxels]\n",
    "            X_train = train_bold[:, selected_voxels]\n",
    "            X = bold[:, selected_voxels]\n",
    "\n",
    "            model = FracRidgeRegressorCV()\n",
    "            model.fit(X_train, Y_train)\n",
    "\n",
    "            Y_pred = model.predict(X)\n",
    "\n",
    "            distances = cosine_distance(torch.from_numpy(Y[None]).float(), torch.from_numpy(Y_pred[:, None]).float())\n",
    "            accuracy = round(two_versus_two(distances, stimulus_ids=stimulus_ids).item() * 100, 2) \n",
    "\n",
    "            print(f'num_voxels={top_k_voxels}, num_repetitions={select_num_repetitions}, num_images={select_num_images}, {accuracy=}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35f30b1-b4af-4834-9181-518c92ce7687",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(nc).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri-preprocessing",
   "language": "python",
   "name": "fmri-preprocessing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
