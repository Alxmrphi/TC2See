{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a948d4c0-59d5-481b-a45f-a360c555e083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from tqdm.notebook import tqdm\n",
    "import nibabel as nib\n",
    "import glmsingle\n",
    "from glmsingle.glmsingle import GLM_single\n",
    "import bids\n",
    "from bids import BIDSLayout\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "dir2 = os.path.abspath('..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "\n",
    "from glmsingle_utils import (\n",
    "    load_results, \n",
    "    plot_results,\n",
    "    save_results\n",
    ")\n",
    "from kamitani import (\n",
    "    load_data,\n",
    "    make_design_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c8116f3-1f48-4b75-9512-3fb34ce1329b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\fmriprep-20.2.4\n"
     ]
    }
   ],
   "source": [
    "# Enter the path to the Kamitani dataset, example: X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\fmriprep-20.2.4\n",
    "dataset_path = Path(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa930813-7551-4217-8a87-fa448950b356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.3084704875946\n"
     ]
    }
   ],
   "source": [
    "# Load layouts, this will take about a minute because pybids is slow\n",
    "\n",
    "t = time.time()\n",
    "dataset_layout = bids.BIDSLayout(dataset_path)\n",
    "print(time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9753ec83-3cb5-48ca-9c96-57542da29edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmri_batch[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77c1db85-e2da-4f3a-8975-885f7769ef60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███████████████▏                                                                                                                                                                                                                    | 8/120 [00:54<12:39,  6.78s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m run_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m9\u001b[39m))\n\u001b[0;32m      4\u001b[0m sessions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperceptionNaturalImageTraining\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m16\u001b[39m)]\n\u001b[1;32m----> 6\u001b[0m fmri_batch, events_dfs, fmri_mask \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_layout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msessions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_ids\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Github Repositories\\Google Drive\\Repositories\\fmri-preprocessing\\kamitani.py:66\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(dataset_layout, subject, sessions, run_ids, space)\u001b[0m\n\u001b[0;32m     64\u001b[0m fmri_batch \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run_image \u001b[38;5;129;01min\u001b[39;00m tqdm(run_images):\n\u001b[1;32m---> 66\u001b[0m     fmri_data \u001b[38;5;241m=\u001b[39m \u001b[43mrun_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_fdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m     fmri_data \u001b[38;5;241m=\u001b[39m fmri_data[fmri_mask]\n\u001b[0;32m     68\u001b[0m     fmri_batch\u001b[38;5;241m.\u001b[39mappend(fmri_data)\n",
      "File \u001b[1;32mg:\\python_env\\fmri-preprocessing\\lib\\site-packages\\nibabel\\dataobj_images.py:355\u001b[0m, in \u001b[0;36mDataobjImage.get_fdata\u001b[1;34m(self, caching, dtype)\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fdata_cache\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# Always return requested data type\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# For array proxies, will attempt to confine data array to dtype\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;66;03m# during scaling\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m caching \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfill\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fdata_cache \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[1;32mg:\\python_env\\fmri-preprocessing\\lib\\site-packages\\nibabel\\arrayproxy.py:391\u001b[0m, in \u001b[0;36mArrayProxy.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;124;03m\"\"\" Read data from file and apply scaling, casting to ``dtype``\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \n\u001b[0;32m    373\u001b[0m \u001b[38;5;124;03m    If ``dtype`` is unspecified, the dtype of the returned array is the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;124;03m        Scaled image data with type `dtype`.\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 391\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_scaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslicer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m         arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mg:\\python_env\\fmri-preprocessing\\lib\\site-packages\\nibabel\\arrayproxy.py:358\u001b[0m, in \u001b[0;36mArrayProxy._get_scaled\u001b[1;34m(self, dtype, slicer)\u001b[0m\n\u001b[0;32m    356\u001b[0m     scl_inter \u001b[38;5;241m=\u001b[39m scl_inter\u001b[38;5;241m.\u001b[39mastype(use_dtype)\n\u001b[0;32m    357\u001b[0m \u001b[38;5;66;03m# Read array and upcast as necessary for big slopes, intercepts\u001b[39;00m\n\u001b[1;32m--> 358\u001b[0m scaled \u001b[38;5;241m=\u001b[39m \u001b[43mapply_read_scaling\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_unscaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslicer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslicer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscl_slope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscl_inter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    360\u001b[0m     scaled \u001b[38;5;241m=\u001b[39m scaled\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mpromote_types(scaled\u001b[38;5;241m.\u001b[39mdtype, dtype), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mg:\\python_env\\fmri-preprocessing\\lib\\site-packages\\nibabel\\volumeutils.py:961\u001b[0m, in \u001b[0;36mapply_read_scaling\u001b[1;34m(arr, slope, inter)\u001b[0m\n\u001b[0;32m    959\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr \u001b[38;5;241m*\u001b[39m slope\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inter \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m--> 961\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43marr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minter\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mreshape(shape)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "subject = '02' # ['01', '02', '03']\n",
    "space = 'T1w'\n",
    "run_ids = list(range(1, 9))\n",
    "sessions = [f'perceptionNaturalImageTraining{i:02}' for i in range(1, 16)]\n",
    "\n",
    "fmri_batch, events_dfs, fmri_mask = load_data(dataset_layout, subject, sessions, run_ids=run_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7798fd-dda0-4d12-84c4-5e8d19de8b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ceba823-95ed-4076-b1ca-212e08ef017b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a1dfbc2938467b8ae48e73024b1e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the fmri mask. \n",
    "# fmriPrep outputs one mask for every functional run, but they are mostly identical\n",
    "# This will grab the mask from the very first one\n",
    "mask_image = dataset_layout.get(\n",
    "    subject=subject, \n",
    "    session='perceptionNaturalImageTraining01', \n",
    "    space=space, \n",
    "    run=1, \n",
    "    desc='brain', \n",
    "    extension='nii.gz'\n",
    ")[0].get_image()\n",
    "fmri_mask = mask_image.get_fdata().astype(bool)\n",
    "H, W, D = fmri_mask.shape\n",
    "\n",
    "# Load the fmri data and apply the mask\n",
    "fmri_batch = []\n",
    "for run_image in tqdm(run_images):\n",
    "    fmri_data = run_image.get_fdata()\n",
    "    fmri_data = fmri_data[fmri_mask]\n",
    "    fmri_batch.append(fmri_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03c55392-add4-45c9-94a2-1aa0e642c5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b0ff1646394bf9a102cb411c05a1d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=2, description='run_id', max=4), IntSlider(value=37, description='d', ma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell for visualizing the fMRI runs\n",
    "all_runs = np.concatenate(fmri_batch)\n",
    "mean, std = all_runs.mean(), all_runs.std()\n",
    "\n",
    "show_volume = np.zeros_like(fmri_mask, dtype=float)\n",
    "_, T = fmri_batch[0].shape\n",
    "\n",
    "@interact(run_id=(0, len(fmri_batch)-1), d=(0, D-1), t=(0, T-1))\n",
    "def show(run_id, d, t):\n",
    "    show_volume[fmri_mask] = fmri_batch[run_id][:, t]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(show_volume[:, :, d], cmap='gray', vmin=mean-2*std, vmax=mean+2*std)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1295e6ba-ab27-435d-b6ad-7553bc1a30f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e88ee5606ed45daaac3987f93a3508d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=2, description='run_id', max=4), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the design matrices\n",
    "\n",
    "# Collect all conditions\n",
    "conditions = []\n",
    "for events_df in events_dfs:\n",
    "    for i, event in events_df.iterrows():\n",
    "        if int(event['event_type']) != 1:\n",
    "            continue\n",
    "        conditions.append(event['stimulus_id'])\n",
    "conditions = list(set(conditions))\n",
    "conditions.sort()\n",
    "conditions = {condition: i  for i, condition in enumerate(conditions)}\n",
    "C = len(conditions)\n",
    "\n",
    "T = fmri_batch[0].shape[-1]\n",
    "\n",
    "# Construct the design matrices\n",
    "design_batch = []\n",
    "for run_id, events_df in enumerate(events_dfs):\n",
    "    design_matrix = np.zeros(shape=(T, C))\n",
    "    \n",
    "    for i, event in events_df.iterrows():\n",
    "        if int(event['event_type']) != 1:\n",
    "            continue\n",
    "        condition_name = event['stimulus_id']\n",
    "        c = conditions[condition_name]\n",
    "        t = round(event['onset'] / tr)\n",
    "        design_matrix[t, c] = 1\n",
    "    design_batch.append(design_matrix)\n",
    "    \n",
    "@interact(run_id=(0, len(design_batch)-1))\n",
    "def show(run_id):\n",
    "    design_matrix = design_batch[run_id]\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.xlabel('Conditions')\n",
    "    plt.ylabel('TRs')\n",
    "    plt.imshow(design_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c1130e2-5488-49cc-951c-b08c834d92d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run1', 'run2']\n"
     ]
    }
   ],
   "source": [
    "# Load previous results\n",
    "runs_path = dataset_path / f'../glmsingle/'\n",
    "previous_runs = [p.name for p in runs_path.iterdir()]\n",
    "print(previous_runs)\n",
    "\n",
    "run_name = 'run2'\n",
    "output_path = runs_path / run_name\n",
    "results_glmsingle = load_results(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f31b60f-9d83-4cfa-8d66-a21e259b80c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or run GLMsingle from scratch\n",
    "\n",
    "#break # set a new run name before running to avoid overwriting old results\n",
    "run_name = 'run_4'\n",
    "\n",
    "glmsingle_obj = GLM_single(dict(\n",
    "    wantlibrary=1,\n",
    "    wantglmdenoise=1,\n",
    "    wantfracridge=1,\n",
    "    wantfileoutputs=[1,1,1,1],\n",
    "    wantmemoryoutputs=[1,1,1,1],\n",
    "))\n",
    "\n",
    "pprint(glmsingle_obj.params)\n",
    "\n",
    "output_path = dataset_path / f'derivatives_TC2See_prdgm/glmsingle/{run_name}'\n",
    "results_glmsingle = glmsingle_obj.fit(\n",
    "    design=design_batch,\n",
    "    data=fmri_batch,\n",
    "    stimdur=8,\n",
    "    tr=tr,\n",
    "    outputdir=str(output_path),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff54e919-d048-4b11-af60-95ec858487de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save nifti files for results\n",
    "save_results(results_glmsingle, output_path, fmri_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71299390-17f6-41e4-b578-fcd67b8ef139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191ef4b5588a4a499c8f395dd426c724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=37, description='d_layer', max=74), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect the results at different layers\n",
    "@interact(d_layer=(0, D-1))\n",
    "def plot_results_layer(d_layer):\n",
    "    plot_results(results_glmsingle, fmri_mask, d_layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri-preprocessing",
   "language": "python",
   "name": "fmri-preprocessing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
