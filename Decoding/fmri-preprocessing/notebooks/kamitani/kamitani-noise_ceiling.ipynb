{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f17515-b571-4dfb-b284-10801472e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from tqdm.notebook import tqdm\n",
    "import nibabel as nib\n",
    "import glmsingle\n",
    "from glmsingle.glmsingle import GLM_single\n",
    "import bids\n",
    "from bids import BIDSLayout\n",
    "from scipy.ndimage import zoom, binary_dilation\n",
    "import h5py\n",
    "import nibabel as nib\n",
    "from einops import rearrange\n",
    "\n",
    "dir2 = os.path.abspath('..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "    \n",
    "from noise_ceiling import (\n",
    "    compute_ncsnr,\n",
    "    compute_nc,\n",
    "    group_repetitions\n",
    ")\n",
    "from kamitani import load_data, convert_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9386563-e781-4220-8225-0ac9616dacc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the path to the Kamitani dataset\n",
    "derivatives_path = Path('X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\')\n",
    "derivatives_path_ssd = Path('D:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\')\n",
    "dataset_path = derivatives_path / 'fmriprep-20.2.4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aaecfb-5b7a-4109-94c2-444bdf54af66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load layouts, this will take about a minute because pybids is slow\n",
    "t = time.time()\n",
    "dataset_layout = bids.BIDSLayout(dataset_path)\n",
    "print(time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d8a518-be3e-4e54-8eb8-57975f0a1f6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crop and prepare the data\n",
    "subjects = ['02', '03']\n",
    "#sessions = [f'perceptionNaturalImageTraining{i:02}' for i in range(1, 16)]\n",
    "sessions = [f'perceptionNaturalImageTest{i:02}' for i in range(1, 4)]\n",
    "space = 'T1w'\n",
    "\n",
    "tr = 2.\n",
    "num_runs = len(sessions) * 8\n",
    "num_trs = 239\n",
    "num_stimuli = 50\n",
    "\n",
    "trend_coeffs = np.stack([np.arange(num_trs), np.ones(shape=num_trs)], axis=1)\n",
    "\n",
    "mask_dilations = 3\n",
    "\n",
    "with h5py.File(derivatives_path_ssd / 'kamitani-test-bold.hdf5', 'w') as f:\n",
    "    for subject in tqdm(subjects):\n",
    "        group = f.require_group(f'sub-{subject}')\n",
    "        mask_image = dataset_layout.get(\n",
    "            subject=subject, \n",
    "            session='perceptionNaturalImageTraining01', \n",
    "            space=space, \n",
    "            run=1, \n",
    "            desc='brain', \n",
    "            extension='nii.gz'\n",
    "        )[0].get_image()\n",
    "        fmri_mask = mask_image.get_fdata().astype(bool)\n",
    "        fmri_mask = binary_dilation(fmri_mask, iterations=mask_dilations)\n",
    "        num_voxels = fmri_mask.sum()\n",
    "        \n",
    "        if 'affine' not in group:\n",
    "            group['affine'] = mask_image.affine\n",
    "        \n",
    "        H, W, D = fmri_mask.shape\n",
    "        if 'fmri_mask' not in group:\n",
    "            group['fmri_mask'] = fmri_mask\n",
    "        \n",
    "        group.require_dataset('bold', shape=(num_runs, num_trs, num_voxels), dtype='f4')\n",
    "        group.require_dataset('bold_mean', shape=(num_runs, num_voxels), dtype='f4')\n",
    "        group.require_dataset('bold_std', shape=(num_runs, num_voxels), dtype='f4')\n",
    "        group.require_dataset('bold_trend', shape=(num_runs, 2, num_voxels), dtype='f4')\n",
    "        group.require_dataset('bold_trend_std', shape=(num_runs, num_voxels), dtype='f4')\n",
    "        group.require_dataset('stimulus_trs', shape=(num_runs, num_stimuli), dtype='i4')\n",
    "        group.require_dataset('stimulus_ids', shape=(num_runs, num_stimuli), dtype='f8')\n",
    "        group.require_dataset('num_runs_per_session', shape=(len(sessions),), dtype='i4')\n",
    "        \n",
    "        fmri_data = []\n",
    "        stimulus_ids = []\n",
    "        run_id = 0\n",
    "        for session_id, session in tqdm(enumerate(sessions)):\n",
    "            events_files = dataset_layout.get(\n",
    "                subject=subject, \n",
    "                session=session, \n",
    "                extension='tsv', \n",
    "                suffix='events',\n",
    "            )\n",
    "            image_files = dataset_layout.get(\n",
    "                subject=subject, \n",
    "                session=session, \n",
    "                space=space, \n",
    "                desc='preproc',\n",
    "                suffix='bold',\n",
    "                extension='nii.gz'\n",
    "            )\n",
    "            group['num_runs_per_session'][session_id] = len(image_files)\n",
    "\n",
    "            for events_file, bids_image in tqdm(list(zip(events_files, image_files))):\n",
    "                bold = bids_image.get_image().get_fdata()\n",
    "                bold = bold[fmri_mask].T\n",
    "                \n",
    "                bold_trend = np.linalg.lstsq(trend_coeffs, bold, rcond=None)[0]\n",
    "                bold_predicted = trend_coeffs @ bold_trend\n",
    "                bold_detrend = bold - bold_predicted\n",
    "\n",
    "                events_df = pd.read_csv(events_file.path, sep='\\t', dtype={'stimulus_id': str})\n",
    "                events_df = events_df[events_df['event_type'] == 1]\n",
    "                stimulus_trs = np.rint(np.array(events_df['onset'] / tr)).astype(int)\n",
    "                stimulus_ids = np.array(events_df['stimulus_id']).astype(float)\n",
    "                \n",
    "                group['bold'][run_id] = bold\n",
    "                group['bold_mean'][run_id] = bold.mean(axis=0)\n",
    "                group['bold_std'][run_id] = bold.std(axis=0)\n",
    "                group['bold_trend'][run_id] = bold_trend\n",
    "                group['bold_trend_std'][run_id] = bold_detrend.std(axis=0)\n",
    "                group['stimulus_trs'][run_id] = stimulus_trs\n",
    "                group['stimulus_ids'][run_id] = stimulus_ids\n",
    "                \n",
    "                run_id += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1226e6ce-ac92-4d36-9b02-754c1637057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives_path = Path('D:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\')\n",
    "bold, stimulus_ids, mask, affine = load_data(\n",
    "    derivatives_path / 'kamitani-bold.hdf5', \n",
    "    'sub-02', \n",
    "    tr_offset=3,\n",
    "    run_normalize='linear_trend',\n",
    "    session_normalize=False\n",
    ")\n",
    "bold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2e0863-5c16-4776-b3a6-c865d48e25a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bold_volume = np.zeros_like(mask, dtype=float)\n",
    "D = nc_volume.shape[2]\n",
    "@interact(b=(0, bold.shape[0]-1), d=(0, D-1))\n",
    "def show(b, d):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    bold_volume[mask] = bold[b]\n",
    "    plt.imshow(bold_volume[:, :, d], cmap='bwr', vmin=-2, vmax=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c593a-f3ba-4fbf-afc9-54e05f1cfc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncsnr = compute_ncsnr(bold, group_repetitions(stimulus_ids, num_repetitions=5))\n",
    "nc = compute_nc(ncsnr, num_averages=1)\n",
    "nc_volume = np.zeros_like(mask, dtype=float)\n",
    "nc_volume[mask] = nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96adef60-0b22-44b9-bd11-232430c0cb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = nc_volume.shape[2]\n",
    "@interact(d=(0, D-1), original=True)\n",
    "def show(d):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(nc_volume[:, :, d], cmap='jet', vmin=0., vmax=30,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2db13f-3830-4825-aa5d-5eef460044ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compare normalizing runs by zscoring versus linear trends\n",
    "\n",
    "subjects = ['sub-02', 'sub-03']\n",
    "run_normalize_modes = ['zscore', 'linear_trend']\n",
    "tr_window = (0, 8)\n",
    "\n",
    "#results = {}\n",
    "for subject in subjects:\n",
    "    subject_path = derivatives_path_ssd / 'noise_ceiling' / subject\n",
    "    subject_path.mkdir(exist_ok=True, parents=True)\n",
    "    for run_normalize in run_normalize_modes:\n",
    "        window_str = f'{tr_window[0] * 2}-{tr_window[1] * 2}'\n",
    "        out_file_name = f'{subject}__window-{window_str}__run_normalize-{run_normalize}__noise-ceiling.nii.gz'\n",
    "        if out_file_name in results:\n",
    "            continue\n",
    "        \n",
    "        nc_series = []\n",
    "        for tr_offset in tqdm(range(tr_window[0], tr_window[1] + 1)):\n",
    "            bold, stimulus_ids, mask, affine = load_data(\n",
    "                derivatives_path_ssd / 'kamitani-bold.hdf5', \n",
    "                subject,\n",
    "                tr_offset=tr_offset,\n",
    "                run_normalize=run_normalize\n",
    "            )\n",
    "            ncsnr = compute_ncsnr(bold, repetition_shape(stimulus_ids, n=5))\n",
    "            nc = compute_nc(ncsnr, num_averages=1)\n",
    "            nc_volume = np.zeros_like(mask, dtype=float)\n",
    "            nc_volume[mask] = nc\n",
    "            nc_series.append(nc_volume)\n",
    "        nc_series = np.stack(nc_series, axis=-1)\n",
    "        \n",
    "        results[out_file_name] = nc_series\n",
    "        image = nib.Nifti1Image(nc_series, affine)\n",
    "        nib.save(image, subject_path / out_file_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847bcd4a-6735-482f-8a02-343f7bbab726",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['sub-02', 'sub-03']\n",
    "tr_window = (0, 8)\n",
    "\n",
    "results = {}\n",
    "for subject in subjects:\n",
    "    subject_path = derivatives_path_ssd / 'noise_ceiling' / subject\n",
    "    subject_path.mkdir(exist_ok=True, parents=True)\n",
    "    window_str = f'{tr_window[0] * 2}-{tr_window[1] * 2}'\n",
    "    out_file_name = f'{subject}__window-{window_str}__session_normalize__noise-ceiling.nii.gz'\n",
    "\n",
    "    nc_series = []\n",
    "    for tr_offset in tqdm(range(tr_window[0], tr_window[1] + 1)):\n",
    "        bold, stimulus_ids, mask, affine = load_data(\n",
    "            derivatives_path_ssd / 'kamitani-bold.hdf5', \n",
    "            subject,\n",
    "            tr_offset=tr_offset,\n",
    "            run_normalize='linear_trend',\n",
    "            session_normalize=True\n",
    "        )\n",
    "        ncsnr = compute_ncsnr(bold, repetition_shape(stimulus_ids, n=5))\n",
    "        nc = compute_nc(ncsnr, num_averages=1)\n",
    "        nc_volume = np.zeros_like(mask, dtype=float)\n",
    "        nc_volume[mask] = nc\n",
    "        nc_series.append(nc_volume)\n",
    "    nc_series = np.stack(nc_series, axis=-1)\n",
    "\n",
    "    results[out_file_name] = nc_series\n",
    "    image = nib.Nifti1Image(nc_series, affine)\n",
    "    nib.save(image, subject_path / out_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943098b3-021f-4a6e-b855-729514c138b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['sub-02', 'sub-03']\n",
    "tr_window = (0, 8)\n",
    "\n",
    "results = {}\n",
    "for subject in subjects:\n",
    "    subject_path = derivatives_path_ssd / 'noise_ceiling' / subject\n",
    "    subject_path.mkdir(exist_ok=True, parents=True)\n",
    "    window_str = f'{tr_window[0] * 2}-{tr_window[1] * 2}'\n",
    "    out_file_name = f'{subject}__window-{window_str}__test__noise-ceiling.nii.gz'\n",
    "\n",
    "    nc_series = []\n",
    "    for tr_offset in tqdm(range(tr_window[0], tr_window[1] + 1)):\n",
    "        bold, stimulus_ids, mask, affine = load_data(\n",
    "            derivatives_path_ssd / 'kamitani-test-bold.hdf5', \n",
    "            subject,\n",
    "            tr_offset=tr_offset,\n",
    "            run_normalize='linear_trend',\n",
    "            session_normalize=False\n",
    "        )\n",
    "        ncsnr = compute_ncsnr(bold, group_repetitions(stimulus_ids, num_repetitions=24))\n",
    "        nc = compute_nc(ncsnr, num_averages=1)\n",
    "        nc_volume = np.zeros_like(mask, dtype=float)\n",
    "        nc_volume[mask] = nc\n",
    "        nc_series.append(nc_volume)\n",
    "    nc_series = np.stack(nc_series, axis=-1)\n",
    "\n",
    "    results[out_file_name] = nc_series\n",
    "    image = nib.Nifti1Image(nc_series, affine)\n",
    "    nib.save(image, subject_path / out_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1b42c0-aa6e-4227-bf59-e660114a572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_series = np.stack(nc_series, axis=-1)\n",
    "results[out_file_name] = nc_series\n",
    "image = nib.Nifti1Image(nc_series, affine)\n",
    "nib.save(image, subject_path / out_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7d3dea-5d4e-4b27-afad-0e90807452e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri-preprocessing",
   "language": "python",
   "name": "fmri-preprocessing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
