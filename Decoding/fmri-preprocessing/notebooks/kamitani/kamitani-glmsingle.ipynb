{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a948d4c0-59d5-481b-a45f-a360c555e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from tqdm.notebook import tqdm\n",
    "import nibabel as nib\n",
    "import glmsingle\n",
    "from glmsingle.glmsingle import GLM_single\n",
    "import bids\n",
    "from bids import BIDSLayout\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "dir2 = os.path.abspath('..')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: \n",
    "    sys.path.append(dir1)\n",
    "\n",
    "from glmsingle_utils import (\n",
    "    load_results, \n",
    "    plot_results,\n",
    "    save_results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8116f3-1f48-4b75-9512-3fb34ce1329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the path to the Kamitani dataset, example: X:\\\\Datasets\\\\Deep-Image-Reconstruction\\\\derivatives\\\\fmriprep-20.2.4\n",
    "dataset_path = Path(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa930813-7551-4217-8a87-fa448950b356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load layouts, this will take about a minute because pybids is slow\n",
    "\n",
    "t = time.time()\n",
    "dataset_layout = bids.BIDSLayout(dataset_path)\n",
    "print(time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5c9d10-9bff-4598-855b-ce549ac40a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There were 15 sessions to acquire training data in this dataset\n",
    "# These three groups of sessions presented the same images in the same runs\n",
    "# Each image in the training set was presented exactly 5 times\n",
    "# It is better to run GLMsingle on the same run from one of these groups so cross validation is possible\n",
    "session_groups = {\n",
    "    'A': [f'perceptionNaturalImageTraining{i:02}' for i in (1, 4, 7, 10, 13)],\n",
    "    'B': [f'perceptionNaturalImageTraining{i:02}' for i in (2, 5, 8, 11, 14)],\n",
    "    'C': [f'perceptionNaturalImageTraining{i:02}' for i in (3, 6, 9, 12, 15)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c1db85-e2da-4f3a-8975-885f7769ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = session_groups['A'] # select one or more session groups\n",
    "subject = '02' # ['01', '02', '03']\n",
    "space = 'T1w'\n",
    "run_ids = [1] # one or more runs\n",
    "tr = 2.\n",
    "\n",
    "run_images = []\n",
    "events_dfs = []\n",
    "for session in sessions:\n",
    "    for run_id in run_ids:\n",
    "\n",
    "        bids_image = dataset_layout.get(\n",
    "            subject=subject, \n",
    "            session=session, \n",
    "            space=space, \n",
    "            run=run_id, \n",
    "            desc='preproc', \n",
    "            extension='nii.gz'\n",
    "        )[0]\n",
    "\n",
    "        events_files = dataset_layout.get(\n",
    "            subject=subject, \n",
    "            session=session, \n",
    "            run=run_id, \n",
    "            extension='tsv', \n",
    "            suffix='events',\n",
    "        )\n",
    "        events_df = pd.read_csv(events_files[0].path, sep='\\t',)# dtype={'stimulus_id': str})\n",
    "\n",
    "        events_dfs.append(events_df)\n",
    "        run_images.append(bids_image.get_image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceba823-95ed-4076-b1ca-212e08ef017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fmri mask. \n",
    "# fmriPrep outputs one mask for every functional run, but they are mostly identical\n",
    "# This will grab the mask from the very first one\n",
    "mask_image = dataset_layout.get(\n",
    "    subject=subject, \n",
    "    session=session, \n",
    "    space=space, \n",
    "    run=run_id, \n",
    "    desc='brain', \n",
    "    extension='nii.gz'\n",
    ")[0].get_image()\n",
    "fmri_mask = mask_image.get_fdata().astype(bool)\n",
    "H, W, D = fmri_mask.shape\n",
    "\n",
    "# Load the fmri data and apply the mask\n",
    "fmri_batch = []\n",
    "for run_image in tqdm(run_images):\n",
    "    fmri_data = run_image.get_fdata()\n",
    "    fmri_data = fmri_data[fmri_mask]\n",
    "    fmri_batch.append(fmri_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c55392-add4-45c9-94a2-1aa0e642c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for visualizing the fMRI runs\n",
    "all_runs = np.concatenate(fmri_batch)\n",
    "mean, std = all_runs.mean(), all_runs.std()\n",
    "\n",
    "show_volume = np.zeros_like(fmri_mask, dtype=float)\n",
    "_, T = fmri_batch[0].shape\n",
    "\n",
    "@interact(run_id=(0, len(fmri_batch)-1), d=(0, D-1), t=(0, T-1))\n",
    "def show(run_id, d, t):\n",
    "    show_volume[fmri_mask] = fmri_batch[run_id][:, t]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(show_volume[:, :, d], cmap='gray', vmin=mean-2*std, vmax=mean+2*std)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb24347d-a455-4a0a-afff-c86e15fd5687",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295e6ba-ab27-435d-b6ad-7553bc1a30f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the design matrices\n",
    "\n",
    "# Collect all conditions\n",
    "conditions = []\n",
    "for events_df in events_dfs:\n",
    "    for i, event in events_df.iterrows():\n",
    "        if int(event['event_type']) != 1:\n",
    "            continue\n",
    "        conditions.append(event['stimulus_id'])\n",
    "conditions = list(set(conditions))\n",
    "conditions.sort()\n",
    "conditions = {condition: i  for i, condition in enumerate(conditions)}\n",
    "C = len(conditions)\n",
    "\n",
    "T = fmri_batch[0].shape[-1]\n",
    "\n",
    "# Construct the design matrices\n",
    "design_batch = []\n",
    "for run_id, events_df in enumerate(events_dfs):\n",
    "    design_matrix = np.zeros(shape=(T, C))\n",
    "    \n",
    "    for i, event in events_df.iterrows():\n",
    "        if int(event['event_type']) != 1:\n",
    "            continue\n",
    "        condition_name = event['stimulus_id']\n",
    "        c = conditions[condition_name]\n",
    "        t = round(event['onset'] / tr)\n",
    "        design_matrix[t, c] = 1\n",
    "    design_batch.append(design_matrix)\n",
    "    \n",
    "@interact(run_id=(0, len(design_batch)-1))\n",
    "def show(run_id):\n",
    "    design_matrix = design_batch[run_id]\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.xlabel('Conditions')\n",
    "    plt.ylabel('TRs')\n",
    "    plt.imshow(design_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1130e2-5488-49cc-951c-b08c834d92d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previous results\n",
    "runs_path = dataset_path / f'../glmsingle/'\n",
    "previous_runs = [p.name for p in runs_path.iterdir()]\n",
    "print(previous_runs)\n",
    "\n",
    "run_name = 'run2'\n",
    "output_path = runs_path / run_name\n",
    "results_glmsingle = load_results(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f31b60f-9d83-4cfa-8d66-a21e259b80c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or run GLMsingle from scratch\n",
    "\n",
    "#break # set a new run name before running to avoid overwriting old results\n",
    "run_name = 'run_4'\n",
    "\n",
    "glmsingle_obj = GLM_single(dict(\n",
    "    wantlibrary=1,\n",
    "    wantglmdenoise=1,\n",
    "    wantfracridge=1,\n",
    "    wantfileoutputs=[1,1,1,1],\n",
    "    wantmemoryoutputs=[1,1,1,1],\n",
    "))\n",
    "\n",
    "pprint(glmsingle_obj.params)\n",
    "\n",
    "output_path = dataset_path / f'derivatives_TC2See_prdgm/glmsingle/{run_name}'\n",
    "results_glmsingle = glmsingle_obj.fit(\n",
    "    design=design_batch,\n",
    "    data=fmri_batch,\n",
    "    stimdur=8,\n",
    "    tr=tr,\n",
    "    outputdir=str(output_path),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff54e919-d048-4b11-af60-95ec858487de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save nifti files for results\n",
    "save_results(results_glmsingle, output_path, fmri_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71299390-17f6-41e4-b578-fcd67b8ef139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the results at different layers\n",
    "@interact(d_layer=(0, D-1))\n",
    "def plot_results_layer(d_layer):\n",
    "    plot_results(results_glmsingle, fmri_mask, d_layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri-preprocessing",
   "language": "python",
   "name": "fmri-preprocessing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
