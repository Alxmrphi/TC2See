{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLMSingle Quality Check\n",
    "\n",
    "The purpose of this notebook is to contrast a standard GLM set of responses over a dataset with the GLMSingle-optimised ones. The example given in the GLMSingle Python demonstration is primarily organised around fitting voxel data, while in this project we are primarily using vertex data. This doesn't mean that there is much of a difference, beyond using the GiFTI files that are split per-hemisphere, but for quick verification / quality checking of the preprocessing steps, it's worth a separate notebook to explain the process. \n",
    "\n",
    "The steps involved in this notebook are: \n",
    "* Pick a single subject's data\n",
    "* Apply GLMSingle to it\n",
    "* Extract the $R{^2}$ value averaged across repetitions \n",
    "* Apply standard GLM to the same data\n",
    "* Also extract the $R{^2}$ value for that model\n",
    "* Calculate $R{^2}$ gain by subtracting canonical GLM betas from the GLMSingle ones\n",
    "* Any positive gain shows increased sensitivity to the GLMSingle process\n",
    "* Positive gain indicates the GLMSingle betas are better fit, which is what we expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "from glmsingle.glmsingle import GLM_single\n",
    "from glmsingle_utils import get_data_and_design_matrices\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_no = 35\n",
    "n_timepoints = 236\n",
    "hemi = 'lh'\n",
    "func_folder = Path('/Users/alxmrphi/Documents/Data/Bird/jamestest/TC2See_35/study/sub-35/sub-35/func')\n",
    "events_folder = Path('/Users/alxmrphi/Documents/Data/Bird/jamestest/Tc2See_35/study/csv_files')\n",
    "\n",
    "design1, data1 = get_data_and_design_matrices(sub_no, func_folder, events_folder, hemi, 1, n_timepoints)\n",
    "design2, data2 = get_data_and_design_matrices(sub_no, func_folder, events_folder, hemi, 1, n_timepoints)\n",
    "design3, data3 = get_data_and_design_matrices(sub_no, func_folder, events_folder, hemi, 1, n_timepoints)\n",
    "design4, data4 = get_data_and_design_matrices(sub_no, func_folder, events_folder, hemi, 1, n_timepoints)\n",
    "design5, data5 = get_data_and_design_matrices(sub_no, func_folder, events_folder, hemi, 1, n_timepoints)\n",
    "design6, data6 = get_data_and_design_matrices(sub_no, func_folder, events_folder, hemi, 1, n_timepoints)\n",
    "\n",
    "data1_ = StandardScaler().fit_transform(data1)\n",
    "data2_ = StandardScaler().fit_transform(data2)\n",
    "data3_ = StandardScaler().fit_transform(data3)\n",
    "data4_ = StandardScaler().fit_transform(data4)\n",
    "data5_ = StandardScaler().fit_transform(data5)\n",
    "data6_ = StandardScaler().fit_transform(data6)\n",
    "\n",
    "data_list = [data1_, data2_, data3_, data4_, data5_, data6_]\n",
    "design_list = [design1, design2, design3, design4, design5, design6]\n",
    "\n",
    "split_val = 118\n",
    "\n",
    "design_list2 = [design_list[0][:split_val,:], design_list[0][split_val:,:], design_list[1][:split_val,:],\n",
    "                design_list[1][split_val:,:], design_list[2][:split_val,:], design_list[2][split_val:,:],\n",
    "                design_list[3][:split_val,:], design_list[3][split_val:,:], design_list[4][:split_val,:],\n",
    "                design_list[4][split_val:,:], design_list[5][:split_val,:], design_list[5][split_val:,:]]\n",
    "\n",
    "data_list2 = [data_list[0][:,:split_val], data_list[0][:,split_val:], data_list[1][:,:split_val],\n",
    "                data_list[1][:,split_val:], data_list[2][:,:split_val], data_list[2][:,split_val:],\n",
    "                data_list[3][:,:split_val], data_list[3][:,split_val:], data_list[4][:,:split_val],\n",
    "                data_list[4][:,split_val:], data_list[5][:,:split_val], data_list[5][:,split_val:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** DIAGNOSTICS ***:\n",
      "There are 12 runs.\n",
      "The number of conditions in this experiment is 300.\n",
      "The stimulus duration corresponding to each trial is 2.00 seconds.\n",
      "The TR (time between successive data points) is 1.97 seconds.\n",
      "The number of trials in each run is: [38, 37, 38, 37, 38, 37, 38, 37, 38, 37, 38, 37].\n",
      "The number of trials for each condition is: [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(18), np.int64(18), np.int64(18), np.int64(18), np.int64(18), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(18), np.int64(18), np.int64(18), np.int64(18), np.int64(18), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(18), np.int64(18), np.int64(18), np.int64(18), np.int64(18), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(18), np.int64(18), np.int64(18), np.int64(18), np.int64(18), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(18), np.int64(18), np.int64(18), np.int64(18), np.int64(18), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)].\n",
      "For each condition, the number of runs in which it appears: [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(12), np.int64(12), np.int64(12), np.int64(12), np.int64(6), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(6), np.int64(12), np.int64(6), np.int64(6), np.int64(12), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(6), np.int64(6), np.int64(12), np.int64(12), np.int64(12), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(6), np.int64(12), np.int64(6), np.int64(6), np.int64(12), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(12), np.int64(12), np.int64(12), np.int64(12), np.int64(12), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)].\n",
      "For each run, how much ending buffer do we have in seconds? [np.float64(1.97), np.float64(15.76), np.float64(1.97), np.float64(15.76), np.float64(1.97), np.float64(15.76), np.float64(1.97), np.float64(15.76), np.float64(1.97), np.float64(15.76), np.float64(1.97), np.float64(15.76)].\n",
      "*** Saving design-related results to ./tmp_output_full/DESIGNINFO.npy. ***\n",
      "*** FITTING DIAGNOSTIC RUN-WISE FIR MODEL ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alxmrphi/miniforge3/envs/glmsingle_demo/lib/python3.10/site-packages/glmsingle/glmsingle.py:659: UserWarning: Warning: You have specified trial onsets that occur less than 8 seconds from the end of at least one of the runs. This may cause estimation problems! As a solution, consider simply omitting specification of these ending trials from the original design matrix.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Saving FIR results to ./tmp_output_full/RUNWISEFIR.npy. ***\n",
      "\n",
      "*** FITTING TYPE-A MODEL (ONOFF) ***\n",
      "\n",
      "fitting model...\n",
      "done.\n",
      "\n",
      "preparing output...\n",
      "done.\n",
      "\n",
      "computing model fits...\n",
      "done.\n",
      "\n",
      "computing R^2...\n",
      "done.\n",
      "\n",
      "computing SNR...\n",
      "done.\n",
      "\n",
      "\n",
      "*** Saving results to ./tmp_output_full/TYPEA_ONOFF.npy. ***\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alxmrphi/miniforge3/envs/glmsingle_demo/lib/python3.10/site-packages/sklearn/mixture/_base.py:270: ConvergenceWarning: Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Setting brain R2 threshold to 0.5888332659826737 ***\n",
      "\n",
      "*** FITTING TYPE-B MODEL (FITHRF) ***\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunks:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunks:  25%|██▌       | 1/4 [00:29<01:27, 29.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunks:  50%|█████     | 2/4 [00:57<00:57, 28.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunks:  75%|███████▌  | 3/4 [01:24<00:27, 27.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunks: 100%|██████████| 4/4 [01:52<00:00, 28.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Saving results to ./tmp_output_full/TYPEB_FITHRF.npy. ***\n",
      "\n",
      "*** DETERMINING GLMDENOISE REGRESSORS ***\n",
      "\n",
      "*** CROSS-VALIDATING DIFFERENT NUMBERS OF REGRESSORS ***\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunks:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunks:  25%|██▌       | 1/4 [00:32<01:36, 32.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunks:  50%|█████     | 2/4 [01:03<01:03, 31.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunks:  75%|███████▌  | 3/4 [01:37<00:32, 32.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n",
      "Warning: One or more regressors are all zeros; we will estimate a 0 weight for those regressors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunks: 100%|██████████| 4/4 [02:10<00:00, 32.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** FITTING TYPE-C MODEL (GLMDENOISE) ***\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunks: 100%|██████████| 4/4 [00:17<00:00,  4.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Saving results to ./tmp_output_full/TYPEC_FITHRF_GLMDENOISE.npy. ***\n",
      "\n",
      "*** FITTING TYPE-D MODEL (GLMDENOISE_RR) ***\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunks: 100%|██████████| 4/4 [04:37<00:00, 69.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Saving results to ./tmp_output_full/TYPED_FITHRF_GLMDENOISE_RR.npy. ***\n",
      "\n",
      "*** All model types done ***\n",
      "\n",
      "*** return model types in results ***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt = dict()\n",
    "opt['wantlibrary'] = 1\n",
    "opt['wantglmdenoise'] = 1\n",
    "opt['wantfracridge'] = 1\n",
    "opt['wantfileoutputs'] = [1,1,1,1]\n",
    "opt['wantmemoryoutputs'] = [1,1,1,1]\n",
    "\n",
    "# running python GLMsingle involves creating a GLM_single object\n",
    "# and then running the procedure using the .fit() routine\n",
    "glmsingle_obj = GLM_single(opt)\n",
    "tr = 1.97\n",
    "stimdur = 2.0\n",
    "\n",
    "results_glmsingle = glmsingle_obj.fit(\n",
    "    design_list2,\n",
    "    data_list2,\n",
    "    stimdur,\n",
    "    tr,\n",
    "    outputdir=f'./tmp_output_full/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_full = np.squeeze(results_glmsingle['typed']['R2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the same data through GLMSingle again but this time only with the canonical HRF to get baseline beta values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** DIAGNOSTICS ***:\n",
      "There are 12 runs.\n",
      "The number of conditions in this experiment is 300.\n",
      "The stimulus duration corresponding to each trial is 2.00 seconds.\n",
      "The TR (time between successive data points) is 1.97 seconds.\n",
      "The number of trials in each run is: [38, 37, 38, 37, 38, 37, 38, 37, 38, 37, 38, 37].\n",
      "The number of trials for each condition is: [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(18), np.int64(18), np.int64(18), np.int64(18), np.int64(18), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(18), np.int64(18), np.int64(18), np.int64(18), np.int64(18), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(18), np.int64(18), np.int64(18), np.int64(18), np.int64(18), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(18), np.int64(18), np.int64(18), np.int64(18), np.int64(18), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(18), np.int64(18), np.int64(18), np.int64(18), np.int64(18), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)].\n",
      "For each condition, the number of runs in which it appears: [np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(12), np.int64(12), np.int64(12), np.int64(12), np.int64(6), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(6), np.int64(12), np.int64(6), np.int64(6), np.int64(12), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(6), np.int64(6), np.int64(12), np.int64(12), np.int64(12), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(6), np.int64(12), np.int64(6), np.int64(6), np.int64(12), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(12), np.int64(12), np.int64(12), np.int64(12), np.int64(12), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)].\n",
      "For each run, how much ending buffer do we have in seconds? [np.float64(1.97), np.float64(15.76), np.float64(1.97), np.float64(15.76), np.float64(1.97), np.float64(15.76), np.float64(1.97), np.float64(15.76), np.float64(1.97), np.float64(15.76), np.float64(1.97), np.float64(15.76)].\n",
      "*** Saving design-related results to ./tmp_output_baseline/DESIGNINFO.npy. ***\n",
      "*** FITTING DIAGNOSTIC RUN-WISE FIR MODEL ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alxmrphi/miniforge3/envs/glmsingle_demo/lib/python3.10/site-packages/glmsingle/glmsingle.py:659: UserWarning: Warning: You have specified trial onsets that occur less than 8 seconds from the end of at least one of the runs. This may cause estimation problems! As a solution, consider simply omitting specification of these ending trials from the original design matrix.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Saving FIR results to ./tmp_output_baseline/RUNWISEFIR.npy. ***\n",
      "\n",
      "*** FITTING TYPE-A MODEL (ONOFF) ***\n",
      "\n",
      "fitting model...\n",
      "done.\n",
      "\n",
      "preparing output...\n",
      "done.\n",
      "\n",
      "computing model fits...\n",
      "done.\n",
      "\n",
      "computing R^2...\n",
      "done.\n",
      "\n",
      "computing SNR...\n",
      "done.\n",
      "\n",
      "\n",
      "*** Saving results to ./tmp_output_baseline/TYPEA_ONOFF.npy. ***\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alxmrphi/miniforge3/envs/glmsingle_demo/lib/python3.10/site-packages/sklearn/mixture/_base.py:270: ConvergenceWarning: Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Setting brain R2 threshold to 0.5888332659826737 ***\n",
      "\n",
      "*** FITTING TYPE-B MODEL (FITHRF) ***\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunks: 100%|██████████| 4/4 [00:07<00:00,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Saving results to ./tmp_output_baseline/TYPEB_FITHRF.npy. ***\n",
      "\n",
      "*** All model types done ***\n",
      "\n",
      "*** return model types in results ***\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "opt = dict() \n",
    "opt['wantlibrary'] = 0 # switch off HRF fitting\n",
    "opt['wantglmdenoise'] = 0 # switch off GLMdenoise\n",
    "opt['wantfracridge'] = 0 # switch off ridge regression\n",
    "# for the purpose of this example we will keep the relevant outputs in memory\n",
    "# and also save them to the disk...\n",
    "# the first two indices are the ON-OFF GLM and the baseline single-trial GLM. \n",
    "# no need to save the third (+ GLMdenoise) and fourth (+ fracridge) outputs\n",
    "# since they will not even be computed\n",
    "opt['wantmemoryoutputs'] = [1,1,0,0] \n",
    "opt['wantfileoutputs'] = [1,1,0,0]\n",
    "\n",
    "glmbaseline_obj = GLM_single(opt)\n",
    "tr = 1.97\n",
    "stimdur = 2.0\n",
    "\n",
    "results_glmbaseline = glmbaseline_obj.fit(\n",
    "    design_list2,\n",
    "    data_list2,\n",
    "    stimdur,\n",
    "    tr,\n",
    "    outputdir=f'./tmp_output_baseline/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typeb is where you would usually extract the fitted HRFs but because it was switched off (`opt['wantlibrary'] = 0`)\n",
    "# in our case, this means it's just the canonical HRF that is applied and so this is the correct R2 to use.\n",
    "r2_baseline = np.squeeze(results_glmbaseline['typeb']['R2'])\n",
    "\n",
    "r2_full = np.squeeze(results_glmsingle['typed']['R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain = r2_full - r2_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "Now we can visualise the $R{^2}$ gain in using GLMSingle over the canonical GLM and plot on the inflated LH surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn\n",
    "import nilearn.datasets as datasets\n",
    "from nilearn import datasets\n",
    "from nilearn import plotting\n",
    "\n",
    "fsaverage = datasets.fetch_surf_fsaverage(mesh='fsaverage')\n",
    "r2_full = np.clip(r2_full, a_min=0, a_max=85)\n",
    "\n",
    "infl = fsaverage.infl_left if hemi == 'lh' else fsaverage.infl_right\n",
    "view = plotting.view_surf(infl, r2_full, symmetric_cmap=False)\n",
    "# view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Gain\n",
    "\n",
    "The gain value is of a much smaller magnitude between both conditions so it makes sense to clip the maximum value to be 10-15 (I choose 15 here). This then reveals patches in the visual cortex, in the medial lobe and along the ventral visual pathway that have increases in R^2 gain of about 10-20%, which represents increase in signal quality over and above the canonical GLM beta weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_clipped = np.clip(gain, a_min=0, a_max=15)\n",
    "view = plotting.view_surf(infl, gain_clipped, symmetric_cmap=True)\n",
    "# view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glmsingle_demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
